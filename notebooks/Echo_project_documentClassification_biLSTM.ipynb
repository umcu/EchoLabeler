{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# add autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1dd8f28e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from keras.models import Sequential\n",
    "from keras import layers, utils\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "\n",
    "from typing import Tuple, Dict, List, Literal"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "os.chdir('T://lab_research/RES-Folder-UPOD/Echo_label/E_ResearchData/2_ResearchData')",
   "id": "32c717711699522f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"The possible classes are:\")\n",
    "print(20*\"---\")\n",
    "print([c.split(\".\")[0] for c in os.listdir('./echo_doc_labels')])"
   ],
   "id": "77edabd68ba18e8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4efa158612b8bcd0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#  settings\n",
    "embedding_dim = 128\n",
    "max_len = 200\n",
    "num_words_in_vocab = 5_000\n",
    "num_epochs = 50\n",
    "num_folds = 10\n",
    "Class = 'pe' # aortic_regurgitation, lv_sys_func, None to run all  \n",
    "batch_size = 128\n",
    "ModelType = 'cnn' # bigru, bilstm, cnn\n",
    "ProcessorType = \"cpu\" if len(tf.config.experimental.list_physical_devices(\"GPU\"))==0 else \"gpu\"\n",
    "Splitting = 'from_file' # CV or from_file\n",
    "UseClassWeights = False\n",
    "LR = 0.0005\n",
    "dilation=2\n",
    "num_layers = 128"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a824afe",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "print(ProcessorType)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "353550069f4de85f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "plt.style.use('ggplot')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96e4a0adc5cce0c1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(probs, labels, threshold=0.5):\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    \n",
    "    y_true = labels\n",
    "    #y_true = tf.keras.backend.eval(y_true)\n",
    "    #y_pred = tf.keras.backend.eval(y_pred)\n",
    "    \n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    prec_macro = precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    prec_weighted = precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    prec_micro = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_macro = recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    recall_weighted = recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    recall_micro = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc_weighted = roc_auc_score(y_true, probs, average = 'weighted')\n",
    "    roc_auc_macro = roc_auc_score(y_true, probs, average = 'macro')\n",
    "    roc_auc_micro = roc_auc_score(y_true, probs, average = 'micro')\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1_macro': f1_macro,\n",
    "               'f1_weighted': f1_weighted,\n",
    "               'f1_micro': f1_micro,\n",
    "               'prec_macro': prec_macro,\n",
    "               'prec_weighted': prec_weighted,\n",
    "               'prec_micro': prec_micro,\n",
    "               'recall_macro': recall_macro,\n",
    "               'recall_weighted': recall_weighted,\n",
    "               'recall_micro': recall_micro,\n",
    "               'roc_auc_macro': roc_auc_macro,\n",
    "               'roc_auc_weighted': roc_auc_weighted,\n",
    "               'roc_auc_micro': roc_auc_micro,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "     \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecd0b0ba39bca6be",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# inference pipe\n",
    "def tokenize_and_pad(x, tokenizer, maxlen = 256):\n",
    "    toks = tokenizer.texts_to_sequences(x)\n",
    "    toks_padded = pad_sequences(toks, padding = 'post', maxlen = maxlen)\n",
    "    return toks_padded\n",
    "\n",
    "def evaluate_model(clf, labels):\n",
    "    probas = clf.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(np.argmax(labels, axis=1),\n",
    "                                 np.argmax(probas, axis=1))\n",
    "\n",
    "    return cf_matrix\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3331f26fd0c509f7",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Stratified cross-validation\n",
    "\n",
    "def fold_indices(targets: pd.Series=None, stratified: bool=True, seed: int=42, numfolds: int=10)->Tuple[List,List]:\n",
    "    if stratified:\n",
    "        splitter = StratifiedKFold(n_splits=numfolds, shuffle=True, random_state=seed)\n",
    "        _Targets = targets\n",
    "    else:\n",
    "        splitter = KFold(n_splits=numfolds, shuffle=True, random_state=seed)\n",
    "        _Targets = None\n",
    "\n",
    "    train_indcs, test_indcs = [], []\n",
    "    for train_index, test_index in splitter.split(X=targets, y=_Targets):\n",
    "        train_indcs.append(train_index)\n",
    "        test_indcs.append(test_index)\n",
    "\n",
    "    return zip(train_indcs, test_indcs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2ce3cf91202770e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "class CustomMetrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(CustomMetrics, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = self.model.predict(self.validation_data[0])\n",
    "        val_targ = self.validation_data[1]\n",
    "\n",
    "        _val_metrics = multi_label_metrics(val_targ, val_predict)\n",
    "        for name, value in _val_metrics.items():\n",
    "            logs['val_' + name] = value\n",
    "\n",
    "        print(\" — val_f1_macro: %f — val_accuracy: %f\" % (logs['val_f1_macro'], logs['val_accuracy']))\n",
    "        return"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4c02977",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def CurrentModel(modelselection: Literal['bigru', 'bilstm', 'cnn'], \n",
    "                 embeddingdim: int=128, \n",
    "                 maxlen: int=256, \n",
    "                 vocabsize: int=50_000,\n",
    "                 numclasses: int=5,\n",
    "                 learningrate: float=0.001,\n",
    "                 num_layers: int=128,\n",
    "                 dilation=4):\n",
    "    model = Sequential()\n",
    "    if modelselection =='bigru':        \n",
    "        model.add(layers.Embedding(vocabsize, embeddingdim, input_length=maxlen))\n",
    "        model.add(layers.Bidirectional(layers.GRU(num_layers)))\n",
    "        model.add(layers.Dense(10, activation = 'relu'))\n",
    "        model.add(layers.Dense(numclasses, activation = 'softmax'))\n",
    "        model.compile(optimizer = optimizers.Adam(learning_rate=learningrate),\n",
    "                      loss = 'categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    elif modelselection =='bilstm':\n",
    "        model.add(layers.Embedding(vocabsize, embeddingdim, input_length=maxlen))\n",
    "        model.add(layers.Bidirectional(layers.LSTM(num_layers)))\n",
    "        model.add(layers.Dense(10, activation = 'relu'))\n",
    "        model.add(layers.Dense(numclasses, activation = 'softmax'))\n",
    "        model.compile(optimizer = optimizers.Adam(learning_rate=learningrate),\n",
    "                      loss = 'categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    elif modelselection =='cnn':\n",
    "        model.add(layers.Embedding(vocabsize, embeddingdim, input_length = maxlen))\n",
    "        model.add(layers.Conv1D(num_layers, 5, activation = 'relu', dilation_rate = dilation))\n",
    "        model.add(layers.GlobalMaxPooling1D())\n",
    "        model.add(layers.Dense(10, activation = 'relu'))\n",
    "        model.add(layers.Dense(numclasses, activation = 'softmax'))\n",
    "        model.compile(optimizer = optimizers.Adam(learning_rate=learningrate),\n",
    "                      loss = 'categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c8d3cd3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def run_model_pipe(x: list, model: Sequential, maxlen: int=256, tokenizer=None):\n",
    "    x_tok = tokenize_and_pad(x, tokenizer=tokenizer, maxlen=maxlen)\n",
    "    return model.predict(x_tok)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d471e0819f26480",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d0028d86cdb445f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "labeled_documents = pd.read_json(f\"./echo_doc_labels/{Class}.jsonl\", lines=True)\n",
    "label_col = 'label' if Class!='merged_labels' else 'labels'\n",
    "target_df = pd.DataFrame.from_records(labeled_documents[label_col])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "num_tokens = labeled_documents.text.apply(lambda x: len(x.split(\" \")))\n",
    "plt.hist(num_tokens, bins=30);"
   ],
   "id": "91a201c2411f947b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "_set = set()\n",
    "for __set in labeled_documents.text.apply(lambda x: set(x.split(\" \"))).values:\n",
    "    _set = _set.union(__set)\n",
    "print(f\"Number of unique tokens: {len(_set)}\")"
   ],
   "id": "49a00fc68e98cfdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2bd53d2d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# load train/test hashes\n",
    "hash_docs_link = pd.read_json(\"./echo_span_labels/reduced_labels/merged_labels.jsonl\", lines=True)[['text', '_input_hash']]\n",
    "train_ids = pd.read_csv('./train_echoid.csv', sep=',').input_hash.unique()\n",
    "test_ids = pd.read_csv('./test_echoid.csv', sep=',').input_hash.unique()\n",
    "\n",
    "labeled_documents['_hash'] = labeled_documents.text.str.strip().apply(lambda x: hash(x))\n",
    "hash_docs_link['_hash'] = hash_docs_link.text.str.strip().apply(lambda x: hash(x))\n",
    "\n",
    "labeled_documents = labeled_documents.merge(hash_docs_link[['_input_hash', '_hash']], \n",
    "                                            on='_hash', how='inner')\n",
    "\n",
    "labeled_documents = labeled_documents.drop_duplicates(subset=['_hash']).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "labeled_documents",
   "id": "6fb6760ea96d4c00",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6632439635dd361f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Expand with label columns\n",
    "if Class == 'merged_labels':\n",
    "    Target_maps = {\n",
    "        _Class: {Label:i for i,Label in enumerate(target_df[Class].unique())}\n",
    "        for _Class in target_df.columns\n",
    "    }\n",
    "else:\n",
    "    Target_maps = {\n",
    "        Class: {Label: i for i,Label in enumerate(labeled_documents['label'].unique())} \n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if Class == 'merged_labels':\n",
    "    DF = labeled_documents[['text', '_input_hash']].join(target_df[Class])\n",
    "else:\n",
    "    DF = labeled_documents[['text', '_input_hash', 'label']]\n",
    "\n",
    "DF.columns = ['sentence', '_input_hash', 'labels']\n",
    "\n",
    "label2id = Target_maps[Class]\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "num_labels = len(label2id)\n",
    "\n",
    "DF= DF.assign(label=DF['labels'].map(label2id))"
   ],
   "id": "b7fbdea0c5b2e0e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a3c68f12e14c3d84",
   "metadata": {},
   "source": [
    "# Make folds"
   ]
  },
  {
   "cell_type": "code",
   "id": "83203825517c00c8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# prepping\n",
    "TrainTestDict = defaultdict(dict)\n",
    "\n",
    "if Splitting == 'from_file':\n",
    "    TrainTestDict[0]['Xtrain'] = DF.loc[DF._input_hash.isin(train_ids)].sentence\n",
    "    TrainTestDict[0]['Xtest'] = DF.loc[DF._input_hash.isin(test_ids)].sentence\n",
    "    \n",
    "    TrainTestDict[0]['ytrain'] = DF.loc[DF._input_hash.isin(train_ids)].labels\n",
    "    TrainTestDict[0]['ytest'] = DF.loc[DF._input_hash.isin(test_ids)].labels\n",
    "    \n",
    "elif Splitting == 'CV':\n",
    "    for k,(train_index, test_index) in enumerate(fold_indices(targets=DF['labels'], stratified=True)):\n",
    "        TrainTestDict[k]['Xtrain'] = DF.iloc[train_index].sentence\n",
    "        TrainTestDict[k]['Xtest'] = DF.iloc[test_index].sentence\n",
    "        \n",
    "        TrainTestDict[k]['ytrain'] = DF.iloc[train_index].labels\n",
    "        TrainTestDict[k]['ytest'] = DF.iloc[test_index].labels\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87a4b47e71c1ca13",
   "metadata": {},
   "source": [
    "## Initiate models"
   ]
  },
  {
   "cell_type": "code",
   "id": "664871e9df2dde6b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "ModelDict = defaultdict(dict)\n",
    "for k,v in TrainTestDict.items():\n",
    "    LSTM_Tokenizer = KerasTokenizer(num_words=num_words_in_vocab)\n",
    "    LSTM_Tokenizer.fit_on_texts(v['Xtrain'])\n",
    "    \n",
    "    vocab_size = len(LSTM_Tokenizer.word_index)+1\n",
    "    num_classes = np.unique(v['ytrain']).shape[0]\n",
    "    \n",
    "    ModelDict[k]['tokenizer'] = LSTM_Tokenizer\n",
    "    ModelDict[k]['model'] = CurrentModel(modelselection=ModelType, \n",
    "                                         embeddingdim=embedding_dim,\n",
    "                                         maxlen=max_len,\n",
    "                                         vocabsize=vocab_size,\n",
    "                                         numclasses=num_classes,\n",
    "                                         learningrate=LR,\n",
    "                                         dilation=dilation,\n",
    "                                         num_layers=num_layers\n",
    "                                         )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26a30b4c2d9bfaf3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "id": "a15851917a011494",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "ResultDict = defaultdict(lambda: defaultdict(list))\n",
    "for k,v in ModelDict.items():\n",
    "    _model =  v['model']\n",
    "    _tokenizer = v['tokenizer']\n",
    "\n",
    "    X_train = _tokenizer.texts_to_sequences(TrainTestDict[k]['Xtrain'])\n",
    "    X_test = _tokenizer.texts_to_sequences(TrainTestDict[k]['Xtest'])\n",
    "\n",
    "    X_train = pad_sequences(X_train, padding = 'post', maxlen=max_len)\n",
    "    X_test = pad_sequences(X_test, padding = 'post', maxlen=max_len)\n",
    "\n",
    "    lb = LabelEncoder()\n",
    "    _y = lb.fit_transform(TrainTestDict[k]['ytrain'])\n",
    "    y_train = utils.to_categorical(_y)\n",
    "\n",
    "    _y = lb.transform(TrainTestDict[k]['ytest'])\n",
    "    y_test = utils.to_categorical(_y)\n",
    "\n",
    "    if UseClassWeights:\n",
    "        PosSum = 1/np.sum(y_train, axis=0)\n",
    "        ClassWeights = dict(enumerate(PosSum/np.min(PosSum)))\n",
    "    else:\n",
    "        ClassWeights = None\n",
    "    \n",
    "    result_list = []\n",
    "    history_list = []\n",
    "    confusion_list = []\n",
    "    for epoch_num in range(1, num_epochs+1):\n",
    "        _history = _model.fit(X_train,\n",
    "                             y_train,                         \n",
    "                             epochs = 1,\n",
    "                             verbose = False,\n",
    "                             validation_split = 0,\n",
    "                             class_weight=ClassWeights,\n",
    "                             batch_size = batch_size)\n",
    "    \n",
    "        y_pred = _model.predict(X_test, verbose=False)\n",
    "        _res = multi_label_metrics(labels=y_test, probs=y_pred)\n",
    "        \n",
    "        result_list.append(_res)\n",
    "        history_list.append({'loss': _history.history['loss'][0], \n",
    "                             'accuracy': _history.history['accuracy'][0]})\n",
    "        confusion_list = {id2label[k]: confusion_matrix(y_test[:,k], np.round(y_pred[:,k]))\n",
    "                          for k in range(len(id2label.keys()))}\n",
    "        \n",
    "        \n",
    "        print(f\"Test: F1 Macro={_res['f1_macro']}\")\n",
    "        \n",
    "    ResultDict[k]['history'] = pd.DataFrame(history_list)\n",
    "    ResultDict[k]['result'] = pd.DataFrame(result_list)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "(ResultDict[k]['result'])",
   "id": "e2c6be701004a612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1e627eadb8f623ba"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(ResultDict[k]['result']['f1_macro'], label='F1 Macro')\n",
    "plt.plot(ResultDict[k]['result']['prec_macro'], label='Precision Macro')\n",
    "plt.plot(ResultDict[k]['result']['recall_macro'], label='Recall Macro')\n",
    "plt.legend(loc='best')"
   ],
   "id": "1bfb9a2f9db3a0d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ead311ab73fa4d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload to huggingface hub",
   "id": "de0495325550a5c7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "93e0914e52fd6c43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nlp_310)",
   "language": "python",
   "name": "python3_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
