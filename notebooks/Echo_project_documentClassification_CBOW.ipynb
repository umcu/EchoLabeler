{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import regex\n",
    "import clinlp\n",
    "import medcat as mc\n",
    "import gensim as gs\n",
    "import spacy\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import FastText, Word2Vec, KeyedVectors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import gc\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('T://lab_research/RES-Folder-UPOD/Echo_label/E_ResearchData/2_ResearchData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aortic_regurgitation.jsonl',\n",
       " 'aortic_stenosis.jsonl',\n",
       " 'diastolic_dysfunction.jsonl',\n",
       " 'lv_dil.jsonl',\n",
       " 'lv_syst_func.jsonl',\n",
       " 'merged_labels.jsonl',\n",
       " 'mitral_regurgitation.jsonl',\n",
       " 'pe.jsonl',\n",
       " 'rv_dil.jsonl',\n",
       " 'rv_syst_func.jsonl',\n",
       " 'tricuspid_regurgitation.jsonl',\n",
       " 'wma.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./echo_doc_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['de', 'het', 'een', 'is', 'bij', 'van', 'met', 'en', 'in', 'voor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class = 'aortic_regurgitation'\n",
    "lemmatize = True\n",
    "lowercase = False\n",
    "num_topics = 5\n",
    "num_words_in_vocab = 5_000\n",
    "weight_matrix = 'count' # count, tfidf, etm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "if lemmatize:\n",
    "    nlp = spacy.load(\"nl_core_news_lg\", disable = ['parser','ner'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_documents = pd.read_json(f\"./echo_doc_labels/{Class}.jsonl\", lines=True)\n",
    "label_col = 'label' if Class!='merged_labels' else 'labels'\n",
    "\n",
    "train_ids = pd.read_csv('./train_echoid.csv', sep=',').input_hash.unique()\n",
    "test_ids = pd.read_csv('./test_echoid.csv', sep=',').input_hash.unique()\n",
    "\n",
    "labeled_documents['_hash'] = labeled_documents.text.str.strip().apply(lambda x: hash(x))\n",
    "labeled_documents = labeled_documents.drop_duplicates(subset=['_hash']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordLists = labeled_documents.text.str.split(\" \").tolist()\n",
    "WordCount = defaultdict(int)\n",
    "for d in WordLists:\n",
    "    for t in d:\n",
    "        WordCount[t.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand with label columns\n",
    "if Class == 'merged_labels':\n",
    "    target_df = pd.DataFrame.from_records(labeled_documents[label_col])\n",
    "    Target_maps = {\n",
    "        _Class: {Label:i for i,Label in enumerate(target_df[Class].unique())}\n",
    "        for _Class in target_df.columns\n",
    "    }\n",
    "else:\n",
    "    Target_maps = {\n",
    "        Class: {Label: i for i,Label in enumerate(labeled_documents['label'].unique())} \n",
    "    }\n",
    "    \n",
    "if Class == 'merged_labels':\n",
    "    DF = labeled_documents[['text', '_input_hash']].join(target_df[Class])\n",
    "else:\n",
    "    DF = labeled_documents[['text', '_input_hash', 'label']]\n",
    "\n",
    "DF.columns = ['sentence', '_input_hash', 'labels']\n",
    "\n",
    "label2id = Target_maps[Class]\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "num_labels = len(label2id)\n",
    "\n",
    "DF= DF.assign(label=DF['labels'].map(label2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.assign(sentence=DF.sentence.str.replace(r'[\\r\\n]', '', regex=True)) \n",
    "\n",
    "if lemmatize:\n",
    "    docs = nlp.pipe(DF.sentence.values)\n",
    "    new_texts = [\" \".join([token.lemma_ for token in doc]) for doc in docs] \n",
    "    DF = DF.assign(sentence = new_texts)\n",
    "\n",
    "if lowercase:\n",
    "    DF = DF.assign(sentence = DF.sentence.str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified cross-validation\n",
    "\n",
    "def fold_indices(targets: pd.Series=None, stratified: bool=True, seed: int=42, numfolds: int=10)->Tuple[List,List]:\n",
    "    if stratified:\n",
    "        splitter = StratifiedKFold(n_splits=numfolds, shuffle=True, random_state=seed)\n",
    "        _Targets = targets\n",
    "    else:\n",
    "        splitter = KFold(n_splits=numfolds, shuffle=True, random_state=seed)\n",
    "        _Targets = None\n",
    "\n",
    "    train_indcs, test_indcs = [], []\n",
    "    for train_index, test_index in splitter.split(X=targets, y=_Targets):\n",
    "        train_indcs.append(train_index)\n",
    "        test_indcs.append(test_index)\n",
    "\n",
    "    return zip(train_indcs, test_indcs)\n",
    "\n",
    "def make_folds(targets: pd.Series=None, \n",
    "               train_test: tuple=None, \n",
    "               n_folds: int=10, \n",
    "               stratified: bool=True,\n",
    "               splitting: str='CV',\n",
    "               label_col: str='labels',\n",
    "               text_col: str='sentence'):\n",
    "\n",
    "    TTDict = defaultdict(dict)\n",
    "    if splitting == 'CV':\n",
    "        for k,(train_index, test_index) in enumerate(fold_indices(targets=targets[label_col], \n",
    "                                                                  stratified=stratified,\n",
    "                                                                  numfolds=n_folds)):\n",
    "            TTDict[k]['Xtrain'] = targets.iloc[train_index][text_col]\n",
    "            TTDict[k]['Xtest'] = targets.iloc[test_index][text_col]\n",
    "            \n",
    "            TTDict[k]['ytrain'] = targets.iloc[train_index][label_col]\n",
    "            TTDict[k]['ytest'] = targets.iloc[test_index][label_col]\n",
    "    else:\n",
    "        train_ids, test_ids = train_test\n",
    "        TTDict[0]['Xtrain'] = targets.loc[targets._input_hash.isin(train_ids)][text_col]\n",
    "        TTDict[0]['Xtest'] = targets.loc[targets._input_hash.isin(test_ids)][text_col]\n",
    "        \n",
    "        TTDict[0]['ytrain'] = targets.loc[targets._input_hash.isin(train_ids)][label_col]\n",
    "        TTDict[0]['ytest'] = targets.loc[targets._input_hash.isin(test_ids)][label_col]\n",
    "    \n",
    "    return TTDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestDict = make_folds(DF, \n",
    "                           (train_ids, test_ids), \n",
    "                           n_folds=10, \n",
    "                           stratified=True, \n",
    "                           splitting='from_file',\n",
    "                           label_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TrainTestDict[0]['Xtrain'].to_frame().assign(num_tokens=TrainTestDict[0]['Xtrain'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE from train/test?\n",
    "\n",
    "#3D echo\n",
    "#Zie verslag status\n",
    "#Geen echovenster\n",
    "#tee 190\n",
    "#HDF 36mnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Topic models using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETM(tfidf_matrix, lda_theta, lda_beta):\n",
    "    # beta_{k,j} : probability of word j, given topic k\n",
    "    # theta_{i,k}: probability of topic k, given document i\n",
    "    # tfidf_matrix\n",
    "    \n",
    "    # Get Gamma_i for all documents\n",
    "    num_topics = lda_theta.shape[1]\n",
    "    AverageSentenceLength = np.mean(np.sum(tfidf_matrix>0, axis=1))\n",
    "    gammas=AverageSentenceLength/np.array(np.sum(tfidf_matrix>0, axis=1))[:,0]\n",
    "    # replace inf-gammas with 0\n",
    "    gammas[np.where(np.isinf(gammas))]=0\n",
    "    \n",
    "    # prep omega\n",
    "    indices = tfidf_matrix.indices\n",
    "    indptr = tfidf_matrix.indptr\n",
    "    z = []\n",
    "    \n",
    "    for d,row in enumerate(tfidf_matrix):\n",
    "        idcs = row.indices\n",
    "        for w in idcs:\n",
    "            omega = 0\n",
    "            for k in range(num_topics):\n",
    "                omega = omega + gammas[d]*lda_theta[d,k]*lda_beta[k, w]\n",
    "            z.append(omega)\n",
    "    omega_sparse = sparse.csr_matrix((z, indices, indptr), shape=tfidf_matrix.shape)\n",
    "    return tfidf_matrix.multiply(omega_sparse)\n",
    "    \n",
    "def SALT(tfidf_matrix, cluster_object=None):\n",
    "    # https://github.com/bagheria/saltclass/blob/master/saltclass/saltclass.py\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bes3\\AppData\\Local\\Temp\\ipykernel_10984\\3164761332.py:9: RuntimeWarning: divide by zero encountered in divide\n",
      "  gammas=AverageSentenceLength/np.array(np.sum(tfidf_matrix>0, axis=1))[:,0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do for each TrainTestDict[k]['Xtrain]\n",
    "\n",
    "test = TrainTestDict[0]['Xtrain']\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=num_topics)\n",
    "TVEC =  CountVectorizer(\n",
    "    max_df=0.95, min_df=2, max_features=num_words_in_vocab, stop_words=STOPWORDS\n",
    ")\n",
    "TFVEC = TfidfVectorizer(\n",
    "    max_df=0.95, min_df=2, max_features=num_words_in_vocab, stop_words=STOPWORDS\n",
    ")\n",
    "test_tf = TVEC.fit_transform(test)\n",
    "LDA.fit(test_tf)\n",
    "\n",
    "lda_theta = LDA.transform(test_tf)\n",
    "lda_beta = LDA.components_ / LDA.components_.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "test_tfidf = TFVEC.fit_transform(test)\n",
    "\n",
    "weight_matrix, gammas = ETM(test_tfidf, lda_theta, lda_beta)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract UMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text -> UMLS_extractor -> [CUI0,.., CUIX] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Cui-embeddings to UMLS-entities with RotatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'cui': emb}\n",
    "Emb_path = r'T:\\\\laupodteam\\AIOS\\Bram\\data\\Supporting_Data\\External_embeddings'\n",
    "rotate_path = os.path.join(Emb_path, 'GraphEmbeddings', 'RotatE_entity2id.wv')\n",
    "cui2vec_rotate = KeyedVectors.load_word2vec_format(rotate_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.75310981e-02,  5.64379245e-03, -2.65905098e-03, -1.43344132e-02,\n",
       "       -1.73746161e-02,  1.22708757e-03,  3.99836563e-02,  1.31232571e-02,\n",
       "       -3.89336539e-03,  1.49966194e-03, -1.92586123e-03, -3.62286181e-03,\n",
       "        1.40360612e-02, -5.31081716e-03, -6.14983141e-02,  5.53463399e-02,\n",
       "       -2.38368288e-02,  4.05533530e-04, -2.74435547e-03,  5.02221147e-03,\n",
       "        2.22005788e-02, -9.90363955e-03, -2.56597484e-03,  2.86204950e-03,\n",
       "        8.67487937e-02, -1.87239784e-03,  2.63481122e-03, -1.13010034e-02,\n",
       "       -2.44271550e-02,  2.22457759e-02, -1.99064147e-02, -3.01551763e-02,\n",
       "       -1.90576899e-03, -2.58410175e-04, -1.71828680e-02, -5.40143922e-02,\n",
       "       -1.80036314e-02, -2.25445590e-04, -1.76690836e-02, -1.08256778e-02,\n",
       "       -1.68524799e-04,  2.40636729e-02, -2.31742300e-02,  1.06420089e-02,\n",
       "        9.03841108e-04, -2.76733632e-03, -7.23636299e-02,  2.03280061e-01,\n",
       "       -7.49604311e-04, -1.40114333e-02,  2.32459754e-02, -9.57354307e-02,\n",
       "       -2.98987143e-02, -3.20645645e-02,  2.00373339e-04, -5.59655987e-02,\n",
       "       -8.90629739e-02, -4.11633141e-02,  5.51339192e-03,  1.09451702e-02,\n",
       "       -7.21216807e-03, -1.74323795e-03,  6.38544001e-03, -3.42934788e-03,\n",
       "        1.53338797e-02, -1.22938994e-02,  1.04690557e-02, -1.15510877e-02,\n",
       "        8.43223035e-02,  3.32784839e-03, -1.09965326e-02,  1.86655447e-02,\n",
       "       -6.23569731e-03, -2.76259929e-02,  6.28844351e-02, -8.80678650e-03,\n",
       "        2.90535726e-02, -4.18165792e-03,  9.86028928e-03,  2.63369661e-02,\n",
       "        3.35035659e-02, -7.34427711e-03, -1.41712278e-03, -1.12872338e-02,\n",
       "       -3.29891853e-02, -1.08889200e-01,  1.28819104e-02, -9.26302467e-03,\n",
       "       -5.81428641e-04, -1.15899052e-02, -9.62198339e-03, -1.41857732e-02,\n",
       "        5.27952425e-02,  1.50667623e-01,  1.34375282e-02, -1.31370034e-02,\n",
       "        1.23803550e-03, -1.52688986e-03,  1.20296627e-02,  9.53207463e-02,\n",
       "        7.48472940e-03,  8.88636615e-03,  2.31860089e-03, -2.34397943e-04,\n",
       "       -3.03620137e-02,  3.60566028e-03, -2.29538628e-03,  1.68733334e-03,\n",
       "       -4.90110414e-03, -1.69405788e-02, -4.25938256e-02,  4.21516784e-02,\n",
       "        4.47091684e-02,  3.00197210e-02, -1.71644781e-02,  3.26600373e-02,\n",
       "        8.36518705e-02, -4.49996704e-04, -1.03794942e-02,  5.58649004e-03,\n",
       "        5.07198758e-02, -9.56614036e-04,  1.97660993e-03,  1.94335822e-02,\n",
       "        1.61854606e-02, -6.08043512e-04, -1.22821694e-02,  4.34440002e-02,\n",
       "       -3.53932828e-02, -2.36122776e-02,  4.98282798e-02, -1.03768222e-02,\n",
       "        3.99912568e-03, -1.30796637e-02, -1.48648307e-01, -8.73836689e-03,\n",
       "       -1.84377143e-03,  3.29706408e-02, -1.48033444e-02, -9.27079618e-02,\n",
       "        2.01438801e-04,  3.15894210e-03,  1.67948380e-01,  8.03985149e-02,\n",
       "       -2.63237320e-02,  1.17302325e-03, -1.65871275e-03, -4.59366441e-02,\n",
       "       -5.86591326e-02,  7.87817240e-02, -1.03901587e-02, -7.62528880e-03,\n",
       "       -9.69273783e-03,  4.33772197e-03,  2.13626190e-03, -4.88233659e-03,\n",
       "       -9.28591490e-02,  5.11891767e-02,  1.56349018e-02,  2.27128970e-03,\n",
       "        3.68592925e-02,  7.77956694e-02, -2.48478781e-02, -2.77426708e-02,\n",
       "       -1.81622282e-02,  5.95577294e-03, -4.90894131e-02, -2.10090689e-02,\n",
       "       -5.26493266e-02,  1.52974864e-02, -1.39306322e-01, -1.22327625e-03,\n",
       "       -4.71831067e-03, -2.41900105e-02, -1.37250012e-04, -8.15250794e-04,\n",
       "        9.30683874e-03,  1.78072776e-03, -2.12313444e-03,  1.72158498e-02,\n",
       "        5.42881666e-03,  5.30686043e-02,  1.69334710e-02, -3.51671455e-03,\n",
       "       -3.83965150e-02, -3.66660580e-03,  3.86169879e-03, -1.43581750e-02,\n",
       "        2.81106401e-03,  4.11368050e-02, -3.14081162e-02, -2.18699761e-02,\n",
       "        9.58317146e-03, -3.10159172e-03,  6.09327015e-03,  6.43719127e-03,\n",
       "        6.49786070e-02,  4.86709848e-02, -2.42877373e-04,  6.06074289e-04,\n",
       "       -9.44059528e-03,  1.51964079e-04,  1.65917363e-03,  3.05395783e-03,\n",
       "       -3.76928947e-03, -1.50578271e-03,  6.97126836e-02,  9.43176523e-02,\n",
       "       -3.66368257e-02, -4.46851291e-02, -1.94455069e-02,  3.66816707e-02,\n",
       "        4.24205698e-02,  3.22344117e-02, -1.08914591e-01, -8.82737562e-02,\n",
       "       -5.69603778e-03, -6.25024587e-02,  1.25736957e-02,  8.74377415e-03,\n",
       "       -4.55514202e-03, -1.87697448e-02, -2.53670057e-03,  1.82583276e-02,\n",
       "        7.67607391e-02,  2.30461117e-02,  1.52666192e-03, -6.16504927e-04,\n",
       "        8.55921488e-03,  4.09784552e-04,  3.05870362e-03, -7.92043749e-04,\n",
       "        2.85742991e-02, -9.32358354e-02, -9.11831018e-03, -8.89707822e-03,\n",
       "       -9.44052517e-05, -2.82855518e-02, -1.77672952e-02, -7.15009542e-03,\n",
       "        1.19823907e-02,  4.08865437e-02,  2.12805327e-02, -8.16428512e-02,\n",
       "        6.69173105e-03,  1.06818071e-02,  3.20924073e-02, -2.55490132e-02,\n",
       "        1.00102844e-02,  1.54511437e-01,  7.74524175e-03, -1.32231088e-02,\n",
       "        9.58499312e-03,  8.41601752e-03, -1.86833274e-02, -9.71940579e-04,\n",
       "        3.73385884e-02,  1.40841966e-02,  3.86414723e-03, -6.99698227e-04,\n",
       "       -6.43845871e-02,  6.59480244e-02,  8.76572207e-02,  1.11942440e-01,\n",
       "       -1.01416647e-01,  7.33993202e-02,  5.93684427e-02, -3.26935947e-02,\n",
       "        1.28454566e-02,  5.41353620e-06, -1.28225517e-02,  1.42643647e-03,\n",
       "       -6.35276549e-03,  3.17615420e-02, -5.74468523e-02,  2.20222063e-02,\n",
       "        5.16707869e-03, -1.17554832e-02, -1.23610459e-02, -9.83565929e-04,\n",
       "       -7.66877260e-04, -1.68498873e-03, -1.52213993e-02, -2.11205729e-03,\n",
       "       -2.39565298e-02,  5.81199378e-02, -1.17969222e-01, -7.63562992e-02,\n",
       "        3.20864171e-02, -2.71369680e-03, -2.56716888e-02, -5.84250875e-03,\n",
       "       -1.75544247e-02,  1.54733723e-02, -5.16895298e-03,  6.77700667e-03,\n",
       "       -5.19445911e-02, -3.42615582e-02,  1.84818998e-01,  1.44653738e-01,\n",
       "        3.79323214e-02,  2.70592421e-03,  1.35020195e-02, -3.31359729e-02,\n",
       "        4.40614522e-02, -7.52366111e-02,  1.45101931e-03, -2.25350246e-04,\n",
       "       -8.63673631e-03, -1.17042568e-02,  2.84466031e-03,  2.20869842e-04,\n",
       "       -1.34030789e-01, -3.48388217e-02,  1.78785194e-02,  2.09742542e-02,\n",
       "        8.34740512e-03,  1.53125515e-02,  2.23528408e-03,  1.95427574e-02,\n",
       "        3.21802474e-03,  1.56084821e-02,  5.49887232e-02, -8.58107302e-03,\n",
       "        5.24910055e-02,  2.22558081e-02,  1.70486537e-03, -6.14502793e-03,\n",
       "        4.21644039e-02, -1.19908322e-02, -3.74473602e-04, -1.68518862e-04,\n",
       "        2.19767261e-02, -1.08553991e-02,  2.82447468e-02, -8.84357840e-04,\n",
       "        1.84735119e-01,  1.13119505e-01,  1.70652140e-02,  2.19091540e-04,\n",
       "        6.89005777e-02,  6.82447106e-02,  6.35303631e-02, -1.06287822e-02,\n",
       "       -1.01688725e-03, -2.06753332e-02, -8.19355100e-02, -3.57905105e-02,\n",
       "        4.78278752e-03,  3.61658097e-03,  2.32835729e-02,  1.76780745e-02,\n",
       "       -1.09069064e-01,  7.58849457e-02, -1.09847181e-03, -7.57119339e-03,\n",
       "        4.61891387e-03,  3.32455784e-02, -2.52405759e-02, -9.92080048e-02,\n",
       "       -3.09390891e-02,  2.26105247e-02, -7.69346580e-03,  1.65704492e-04,\n",
       "       -5.59909008e-02,  2.55697966e-03, -2.36301217e-02,  6.33149296e-02,\n",
       "       -2.25860812e-02,  3.18802777e-03, -5.63924350e-02,  5.65751046e-02,\n",
       "        1.23134732e-01, -2.19027810e-02, -3.36311315e-03,  1.60463306e-03,\n",
       "       -5.98258600e-02,  3.65521647e-02,  1.10817747e-02, -4.09195200e-03,\n",
       "       -2.77557746e-02, -7.22281449e-03,  5.51866554e-03,  3.30647714e-02,\n",
       "       -1.73290670e-02, -5.82881272e-02, -5.23449257e-02,  3.09376456e-02,\n",
       "       -2.25724129e-04, -6.98170764e-03,  1.16072774e-01, -9.95638296e-02,\n",
       "        5.92821045e-03,  4.36475850e-04, -1.08406506e-02,  8.63286555e-02,\n",
       "        5.39827021e-03, -3.01946066e-02, -1.27854152e-02, -1.88817084e-02,\n",
       "       -5.14414534e-02,  7.10102767e-02,  9.36236139e-03,  1.13952695e-03,\n",
       "       -1.32925273e-03,  8.63504875e-03,  1.18889997e-03,  6.76097423e-02,\n",
       "        6.39684498e-02, -5.02066780e-03, -9.43639651e-02, -9.40281227e-02,\n",
       "       -5.38771674e-02,  6.40666634e-02, -5.23192575e-03,  5.16168482e-04,\n",
       "       -9.69713647e-03,  9.42760520e-03, -1.38136977e-02,  1.15118411e-04,\n",
       "       -6.25509815e-03, -4.17528152e-02, -6.20788103e-03, -3.16074453e-02,\n",
       "       -2.00887099e-02, -9.84486006e-03, -2.55713575e-02,  6.09944388e-03,\n",
       "       -3.39505239e-03, -2.94193812e-03, -3.39306742e-02, -1.83595810e-02,\n",
       "        1.42387263e-02,  2.63297223e-02,  4.68283705e-02, -1.46326479e-02,\n",
       "       -2.54188105e-03, -1.25685968e-02,  5.48637751e-03,  5.57780638e-03,\n",
       "        1.18434345e-02,  5.04256934e-02,  1.79848331e-03,  6.01834198e-03,\n",
       "       -6.02521049e-03,  2.82090064e-02,  9.55180265e-03,  2.28268877e-02,\n",
       "        1.28837377e-01, -3.89831252e-02,  5.19703841e-03, -1.75196938e-02,\n",
       "        2.88715848e-04,  1.33271918e-01, -1.24949597e-01, -1.43431183e-02,\n",
       "        5.63855283e-02, -2.94802506e-02, -4.48389053e-02, -3.02460156e-02,\n",
       "        3.07778064e-02,  1.09806389e-01,  8.71559791e-03, -7.03768688e-04,\n",
       "        9.36004296e-02,  9.42069571e-03,  3.62063845e-04, -2.95112055e-04,\n",
       "        4.64750174e-03, -1.24277920e-02,  5.38053690e-04, -1.33191556e-04,\n",
       "        2.63307039e-02, -1.24670319e-01, -5.56102432e-02,  1.77590782e-03,\n",
       "        8.17591138e-03,  9.88058932e-03, -7.20188161e-03,  1.27003267e-02,\n",
       "        8.33153259e-03, -1.42978188e-02, -5.16918779e-04, -1.37707160e-03,\n",
       "       -5.52440546e-02,  1.19677847e-02, -4.12896499e-02, -5.94384782e-02,\n",
       "       -5.52955549e-03, -3.32932058e-03,  3.45672704e-02,  2.44049099e-03,\n",
       "       -1.01078793e-01,  5.34083098e-02, -3.58220364e-04,  6.00657007e-03,\n",
       "       -4.36401181e-03,  1.13744261e-02, -5.70513483e-04, -3.84202562e-02,\n",
       "       -1.86628057e-03, -3.13271582e-02,  4.78154607e-03,  1.59245916e-02,\n",
       "        5.62795019e-03, -3.61701474e-03,  4.45650611e-03, -2.48524616e-03,\n",
       "        2.08596718e-02, -3.06828357e-02, -6.05278648e-03, -1.31053060e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cui2vec_rotate['C0411888']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Word2vec from pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'token': embedding}\n",
    "# load clinical NLP embeddings, hear we are limited to fourgrams\n",
    "StaticEmbedding = KeyedVectors.load('path_to_embeddings.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jegormeister/robbert-v2-dutch-base-mqa-finetuned, \n",
    "# textgain/allnli-GroNLP-bert-base-dutch-cased,\n",
    "# NetherlandsForensicInstitute/robbert-2022-dutch-sentence-transformers\n",
    "SentenceModel = SentenceTransformer('FremyCompany/BioLORD-2023-M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate per document using PoS, LDA, UMLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nlp_310)",
   "language": "python",
   "name": "python3_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
