{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import deduce\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import phrases\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dill"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context:\n",
    "* $100$ K echocardiographic reports available. \n",
    "* we want to extract diagnoses regarding the left-ventricle function\n",
    "* we have $5000$ reports with labeled spans.\n",
    "\n",
    "# Goal:\n",
    "Train a \"model\" that can\n",
    "1. identify the spans\n",
    "2. classify the spans\n",
    "\n",
    "# Approach: MedCAT - MetaCAT\n",
    "\n",
    "## Two-step approach\n",
    "\n",
    "* unsupervised training on the documents\n",
    "* add a single custom entity with a custom identifier\n",
    "* train a model to identify the custom entities\n",
    "* supervised training on the meta-annotations of the entities\n",
    "\n",
    "## One-step approach\n",
    "\n",
    "* unsupervised training on the documents\n",
    "* add custom entities based on the spans and their labels\n",
    "* train a model to identify the custom entities\n",
    "\n",
    "# Approach: biLSTM/transformer\n",
    "\n",
    "## Two-step approach\n",
    "\n",
    "* Train a model to identify the spans: self-supervision by random selecting non-span ranges as negative examples\n",
    "* Train a model to classify the spans: supervised based on the labeled spans \n",
    "* Combine the model in one pipeline\n",
    "\n",
    "## One-step approach\n",
    "* Assign a label to each span\n",
    "* Train a model to identify the spans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Medcat modelpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "# extract the environment variable 'medcat_pack'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\medcat\\cat.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from medcat.cat import CAT\n",
    "from medcat.vocab import Vocab\n",
    "from medcat.cdb import CDB\n",
    "from medcat.config import Config\n",
    "from medcat.meta_cat import MetaCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_medcat_path = os.getenv('medcat_pack')\n",
    "pack_location = 'umls-dutch-v1-10_echo'\n",
    "prep_medcat = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_path = 'T://lab_research/RES-Folder-UPOD/Echo_label/E_ResearchData/2_ResearchData'\n",
    "# load the jsonl in a dataframe\n",
    "texts = pd.read_json(os.path.join(echo_path, 'outdb_140423.jsonl'), lines=True)\n",
    "#texts_zipped = zip(texts['text'], texts['_input_hash'], texts['_task_hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indcs = pd.read_csv(os.path.join(echo_path, 'train_echoid.csv'), sep=',')\n",
    "test_indcs = pd.read_csv(os.path.join(echo_path, 'test_echoid.csv'), sep=',')\n",
    "\n",
    "train_indcs = train_indcs[train_indcs.input_hash.notna()]\n",
    "test_indcs = test_indcs[test_indcs.input_hash.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_INPUT_HASH = set(train_indcs['input_hash'].astype(int).to_list())\n",
    "TRAIN_TASK_HASH = set(train_indcs['task_hash'].astype(int).to_list())\n",
    "\n",
    "TEST_INPUT_HASH = set(test_indcs['input_hash'].astype(int).to_list())\n",
    "TEST_TASK_HASH = set(test_indcs['task_hash'].astype(int).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = texts.loc[texts._input_hash.isin(TRAIN_INPUT_HASH)]\n",
    "texts_test = texts.loc[texts._input_hash.isin(TEST_INPUT_HASH)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make splitted data\n",
    "\n",
    "* MedCAT train files\n",
    "* class-dictionary with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medcat_json(filename: str=None, HashSet: set=False, ClassName: str=None):\n",
    "    texts = pd.read_json(filename, lines=True)\n",
    "    output = {\"projects\": [{\n",
    "                \"name\": ClassName,\n",
    "                \"id\": 42,\n",
    "                \"cuis\": \"\",\n",
    "                \"tuis\": \"\",\n",
    "                \"documents\": None\n",
    "            }]}\n",
    "    \n",
    "    documents = []\n",
    "    for i, _row in enumerate(texts.iterrows()):\n",
    "        row = _row[1]\n",
    "        if (row[\"_input_hash\"] in HashSet) | (HashSet is False):\n",
    "            txt = row['text']\n",
    "            id = i\n",
    "            input_hash = row[\"_input_hash\"]\n",
    "            task_hash = row[\"_task_hash\"]\n",
    "            annotations = []\n",
    "            for j, ann in enumerate(row[\"spans\"]):\n",
    "                res = {}\n",
    "                res['user'] = 'BVE'\n",
    "                res['cui'] = 123\n",
    "                res['id'] = j\n",
    "                res['start'] = ann['start']\n",
    "                res['end'] = ann['end']\n",
    "                res['value'] = txt[ann['start']:ann['end']]\n",
    "                res['validated'] = True\n",
    "                res['correct'] = True\n",
    "                res['deleted'] = False\n",
    "                res['alternative'] = False\n",
    "                res['killed'] = False\n",
    "                res[\"meta_anns\"] = {\n",
    "                    ClassName: {\n",
    "                        \"name\": ClassName,\n",
    "                        \"validated\": True,\n",
    "                        \"accuracy\": 1.0,\n",
    "                        \"value\": ann['label']\n",
    "                    }\n",
    "                }\n",
    "                annotations.append(res)\n",
    "            doc = {\n",
    "                'id': id,\n",
    "                'text': txt,\n",
    "                'input_hash': input_hash,\n",
    "                'task_hash': task_hash,\n",
    "                'annotations': annotations         \n",
    "            }\n",
    "            documents.append(doc)\n",
    "    output['projects'][0]['documents'] = documents\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(os.path.join(echo_path, 'echo_span_labels'))\n",
    "merged_index = [i for i,t in enumerate(class_names) \n",
    "                    if ('merged' in t) | ('old' in t)]\n",
    "merged_index = sorted(merged_index, reverse=True)\n",
    "\n",
    "for mind in merged_index:\n",
    "    class_names.pop(mind)\n",
    "class_ds = defaultdict(dict)\n",
    "\n",
    "for file_name in class_names:\n",
    "    _class = file_name.split(\".\")[0]\n",
    "    fn = os.path.join(echo_path, 'echo_span_labels', file_name)\n",
    "    class_ds[_class]['ds'] = pd.read_json(fn, lines=True)\n",
    "    \n",
    "    #TODO: has to be refactored\n",
    "    medcat_json = get_medcat_json(fn, TRAIN_INPUT_HASH, _class)\n",
    "    medcat_out = os.path.join(echo_path, 'medcat_labels', 'train', f'medcat_{_class}.json')\n",
    "    json.dump(medcat_json, open(medcat_out, 'w'))\n",
    "    class_ds[_class]['train_location'] = medcat_out\n",
    "    \n",
    "    medcat_json = get_medcat_json(fn, TEST_INPUT_HASH, _class)\n",
    "    medcat_out = os.path.join(echo_path, 'medcat_labels', 'test', f'medcat_{_class}.json')\n",
    "    json.dump(medcat_json, open(medcat_out, 'w'))\n",
    "    class_ds[_class]['test_location'] = medcat_out\n",
    "    \n",
    "    class_ds[_class]['labels'] = set([span_dict['label'] \n",
    "                                        for span_list in class_ds[_class]['ds']['spans'].tolist()\n",
    "                                        for span_dict in span_list])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning for NER+L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCAT = CAT.load_model_pack(os.path.join(base_medcat_path, pack_location))\n",
    "\n",
    "MCAT.train(texts_train.text.values, \n",
    "            nepochs=3, \n",
    "            progress_print=10,  \n",
    "            is_resumed=True)\n",
    "MCAT.create_model_pack(base_medcat_path + \"/umls-dutch-v1-10_echo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add label spans from Prodigy annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 22.18it/s]\n"
     ]
    }
   ],
   "source": [
    "span_sets = defaultdict(set)\n",
    "for _class, dsd in tqdm(class_ds.items()):\n",
    "        ds = dsd['ds']\n",
    "        span_set = set()\n",
    "        span_list = []\n",
    "        ds = ds[ds._input_hash.isin(TRAIN_INPUT_HASH)]\n",
    "        for k, (_spans, text) in enumerate(zip(ds[ds.spans.notna()].spans.values,\n",
    "                                            ds[ds.spans.notna()].text.values)):\n",
    "            for _span in _spans:\n",
    "                start, end = _span['start'], _span['end']\n",
    "                span_set.add(text[start:end])\n",
    "                span_list.append(text[start:end])\n",
    "        span_sets[_class] = span_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: interesting to add variants without the abbreviations?\n",
    "# TODO: including paraphrasing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class, span_set in tqdm(span_sets.items()):\n",
    "    for _span in span_set:\n",
    "        MCAT.add_and_train_concept(cui=_class,\n",
    "                                name=_span, \n",
    "                                do_add_concept=True,\n",
    "                                negative=False,\n",
    "                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning for NER+L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCAT.train_supervised(data_path=os.path.join(base_medcat_path, \n",
    "                                 \"umls-dutch-v1-10_echo\",\n",
    "                                 \"input/ner_l_anno/trainer_export.json\"), \n",
    "                      nepochs=4,\n",
    "                      print_stats=0,\n",
    "                      use_filters=False)\n",
    "medcat_path = base_medcat_path + \"/umls-dutch-v1-10_echoV2\"\n",
    "MCAT.create_model_pack(medcat_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning of MetaCAT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MCAT from file\n",
    "medcat_path = os.path.join(base_medcat_path, 'umls-dutch-v1-10_echoV2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCAT = CAT.load_model_pack(medcat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE, ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer from negation_model\n",
    "# tokenizer folder \n",
    "tok_folder = 'T:/laupodteam/AIOS/Bram/language_modeling/Clinical_embeddings/bigrams/with_tokenizer/v2/tokenizer'\n",
    "emb_folder = 'T:/laupodteam/AIOS/Bram/language_modeling/Clinical_embeddings/bigrams/with_tokenizer/v2/SG'\n",
    "tokenizer = ByteLevelBPETokenizer.from_file(os.path.join(tok_folder, 'vocab.json'), \n",
    "                                            os.path.join(tok_folder, 'merges.txt'))\n",
    "wrapped_tokenizer = TokenizerWrapperBPE(hf_tokenizers=tokenizer)\n",
    "wrapped_tokenizer.save(medcat_path + \"/assets/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "vec_path = os.path.join(emb_folder, 'sg')\n",
    "print(vec_path)\n",
    "w2v = KeyedVectors.load(vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix\n",
    "embeddings = []\n",
    "words_not_present = []\n",
    "\n",
    "for i in range(tokenizer.get_vocab_size()):\n",
    "    word = tokenizer.id_to_token(i)\n",
    "    if word in w2v:\n",
    "        embeddings.append(w2v[word])\n",
    "    else:\n",
    "        words_not_present.append(i)\n",
    "        embeddings.append(np.random.random(300))\n",
    "        \n",
    "mean_vector = np.mean(embeddings, axis=0)\n",
    "\n",
    "for i in words_not_present:\n",
    "    embeddings[i] = mean_vector\n",
    "\n",
    "# Save the embeddings\n",
    "embeddings_array = np.array(embeddings)\n",
    "np.save(open(medcat_path+\"/assets/embeddings/embedding.npy\", \n",
    "             'wb'), embeddings_array)\n",
    "\n",
    "print(f\"Words not present:{len(words_not_present)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class, d in class_ds.items():\n",
    "    if _class != 'normal':\n",
    "        print(f\"Commencing training of biLSTM-span for {_class}...\")\n",
    "        config_metacat = ConfigMetaCAT()\n",
    "        config_metacat.general['category_name'] = _class\n",
    "        config_metacat.train['nepochs'] = 25\n",
    "        config_metacat.train['score_average'] = 'weighted'\n",
    "        config_metacat.model['hidden_size'] = 256\n",
    "        config_metacat.model['input_size'] = 300\n",
    "        config_metacat.model['dropout'] = 0.3\n",
    "        config_metacat.model['num_layers'] = 3\n",
    "        config_metacat.model['num_directions'] = 2\n",
    "        config_metacat.model['nclasses'] = len(d['labels'])\n",
    "        config_metacat.model['model_name'] = 'lstm'\n",
    "        \n",
    "        meta_cat = MetaCAT(tokenizer=wrapped_tokenizer,\n",
    "                    embeddings=embeddings_array, \n",
    "                    config=config_metacat)\n",
    "        \n",
    "        train_path = d['train_location']\n",
    "        model_path = os.path.join(medcat_path, f\"meta_{_class}\")\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        \n",
    "        meta_cat.train(json_path=train_path, \n",
    "                        save_dir_path=model_path)\n",
    "        \n",
    "        meta_cat.save(save_dir_path=model_path)\n",
    "        # now manually add the model to the model_pack...\n",
    "        label_dict = config_metacat.general.category_value2id\n",
    "        \n",
    "        # add to config\n",
    "        medcat_config = json.load(open(os.path.join(medcat_path, 'model_card.json'), 'r'))\n",
    "        \n",
    "        # add to \"MetaCAT models\" list\n",
    "        medcat_config[\"MetaCAT models\"].append({\n",
    "                      \"Category Name\": _class,\n",
    "                      \"Description\": \"No description\",\n",
    "                      \"Classes\": label_dict,\n",
    "                        \"Model\": \"lstm\"\n",
    "                    })\n",
    "        # write config to .json\n",
    "        json.dump(medcat_config, open(os.path.join(medcat_path, 'model_card.json'), 'w'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load  new model pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'nl_core_news_lg' (3.1.0) was trained with spaCy v3.1.0 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "MCATnew = CAT.load_model_pack(os.path.join(medcat_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    L.V. is niet vergroot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">concept</span>\n",
       "</mark>\n",
       " , licht verdikte L.V mass 116gr/m2 licht verhoogd.. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    LVH\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">concept</span>\n",
       "</mark>\n",
       " met asymaetrische verdikking. maximale septumdikte van 14mm .Mid anterieure septum geringe hypokinesie,  ook strain daar lage piek strain . Strainpatroon zeer suggestief voor een HCM. Licht verminderde EF van ong. 49%,  GLS-18%. is ook wat laag. \r<br>Geen klepafwijkingen.\r<br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Goede R.V. functie.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">concept</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 123\n",
    "doc = MCATnew(texts.text.values[i])\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_with_conf(ent):\n",
    "    result_dict = {}\n",
    "    for k, v in ent._.meta_anns.items():\n",
    "        result_dict[k] = v['value']\n",
    "        result_dict[f'conf_{k}'] = v['confidence']\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = MCATnew(texts.text.values[i])\n",
    "inds = []\n",
    "res = []\n",
    "for ent in doc.ents:\n",
    "    inds.append(ent.text)\n",
    "    res.append(create_dict_with_conf(ent))\n",
    "    \n",
    "res_df = pd.DataFrame(res, index=inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aortic_regurgitation</th>\n",
       "      <th>conf_aortic_regurgitation</th>\n",
       "      <th>aortic_stenosis</th>\n",
       "      <th>conf_aortic_stenosis</th>\n",
       "      <th>diastolic_dysfunction</th>\n",
       "      <th>conf_diastolic_dysfunction</th>\n",
       "      <th>lv_dil</th>\n",
       "      <th>conf_lv_dil</th>\n",
       "      <th>lv_syst_func</th>\n",
       "      <th>conf_lv_syst_func</th>\n",
       "      <th>...</th>\n",
       "      <th>pe</th>\n",
       "      <th>conf_pe</th>\n",
       "      <th>rv_dil</th>\n",
       "      <th>conf_rv_dil</th>\n",
       "      <th>rv_syst_func</th>\n",
       "      <th>conf_rv_syst_func</th>\n",
       "      <th>tricuspid_regurgitation</th>\n",
       "      <th>conf_tricuspid_regurgitation</th>\n",
       "      <th>wma</th>\n",
       "      <th>conf_wma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L.V. is niet vergroot</th>\n",
       "      <td>aortic_valve_native_regurgitation_not_present</td>\n",
       "      <td>0.981397</td>\n",
       "      <td>aortic_valve_native_stenosis_not_present</td>\n",
       "      <td>0.987066</td>\n",
       "      <td>lv_dias_func_normal</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>lv_dil_normal</td>\n",
       "      <td>0.694518</td>\n",
       "      <td>lv_sys_func_mild</td>\n",
       "      <td>0.504134</td>\n",
       "      <td>...</td>\n",
       "      <td>pe_not_present</td>\n",
       "      <td>0.822488</td>\n",
       "      <td>rv_dil_normal</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>rv_sys_func_mild</td>\n",
       "      <td>0.807520</td>\n",
       "      <td>tricuspid_valve_native_regurgitation_not_present</td>\n",
       "      <td>0.877692</td>\n",
       "      <td>wma_present</td>\n",
       "      <td>0.980276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVH</th>\n",
       "      <td>aortic_valve_native_regurgitation_not_present</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>aortic_valve_native_stenosis_sclerosis</td>\n",
       "      <td>0.667423</td>\n",
       "      <td>lv_dias_func_mild</td>\n",
       "      <td>0.471018</td>\n",
       "      <td>lv_dil_normal</td>\n",
       "      <td>0.838429</td>\n",
       "      <td>lv_sys_func_normal</td>\n",
       "      <td>0.981571</td>\n",
       "      <td>...</td>\n",
       "      <td>pe_not_present</td>\n",
       "      <td>0.992050</td>\n",
       "      <td>rv_dil_normal</td>\n",
       "      <td>0.998393</td>\n",
       "      <td>rv_sys_func_normal</td>\n",
       "      <td>0.993181</td>\n",
       "      <td>tricuspid_valve_native_regurgitation_not_present</td>\n",
       "      <td>0.673197</td>\n",
       "      <td>wma_present</td>\n",
       "      <td>0.926663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goede R.V. functie.</th>\n",
       "      <td>aortic_valve_native_regurgitation_not_present</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>aortic_valve_native_stenosis_not_present</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>lv_dias_func_normal</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>lv_dil_normal</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>lv_sys_func_normal</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>...</td>\n",
       "      <td>pe_not_present</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>rv_dil_present</td>\n",
       "      <td>0.989306</td>\n",
       "      <td>rv_sys_func_normal</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>tricuspid_valve_native_regurgitation_trace</td>\n",
       "      <td>0.509716</td>\n",
       "      <td>wma_not_present</td>\n",
       "      <td>0.664993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                aortic_regurgitation  \\\n",
       "L.V. is niet vergroot  aortic_valve_native_regurgitation_not_present   \n",
       "LVH                    aortic_valve_native_regurgitation_not_present   \n",
       "Goede R.V. functie.    aortic_valve_native_regurgitation_not_present   \n",
       "\n",
       "                       conf_aortic_regurgitation  \\\n",
       "L.V. is niet vergroot                   0.981397   \n",
       "LVH                                     0.999951   \n",
       "Goede R.V. functie.                     0.999994   \n",
       "\n",
       "                                                aortic_stenosis  \\\n",
       "L.V. is niet vergroot  aortic_valve_native_stenosis_not_present   \n",
       "LVH                      aortic_valve_native_stenosis_sclerosis   \n",
       "Goede R.V. functie.    aortic_valve_native_stenosis_not_present   \n",
       "\n",
       "                       conf_aortic_stenosis diastolic_dysfunction  \\\n",
       "L.V. is niet vergroot              0.987066   lv_dias_func_normal   \n",
       "LVH                                0.667423     lv_dias_func_mild   \n",
       "Goede R.V. functie.                0.999920   lv_dias_func_normal   \n",
       "\n",
       "                       conf_diastolic_dysfunction         lv_dil  conf_lv_dil  \\\n",
       "L.V. is niet vergroot                    0.927207  lv_dil_normal     0.694518   \n",
       "LVH                                      0.471018  lv_dil_normal     0.838429   \n",
       "Goede R.V. functie.                      0.999206  lv_dil_normal     0.999795   \n",
       "\n",
       "                             lv_syst_func  conf_lv_syst_func  ...  \\\n",
       "L.V. is niet vergroot    lv_sys_func_mild           0.504134  ...   \n",
       "LVH                    lv_sys_func_normal           0.981571  ...   \n",
       "Goede R.V. functie.    lv_sys_func_normal           0.999352  ...   \n",
       "\n",
       "                                   pe   conf_pe          rv_dil  conf_rv_dil  \\\n",
       "L.V. is niet vergroot  pe_not_present  0.822488   rv_dil_normal     0.999218   \n",
       "LVH                    pe_not_present  0.992050   rv_dil_normal     0.998393   \n",
       "Goede R.V. functie.    pe_not_present  0.999676  rv_dil_present     0.989306   \n",
       "\n",
       "                             rv_syst_func  conf_rv_syst_func  \\\n",
       "L.V. is niet vergroot    rv_sys_func_mild           0.807520   \n",
       "LVH                    rv_sys_func_normal           0.993181   \n",
       "Goede R.V. functie.    rv_sys_func_normal           0.999907   \n",
       "\n",
       "                                                tricuspid_regurgitation  \\\n",
       "L.V. is niet vergroot  tricuspid_valve_native_regurgitation_not_present   \n",
       "LVH                    tricuspid_valve_native_regurgitation_not_present   \n",
       "Goede R.V. functie.          tricuspid_valve_native_regurgitation_trace   \n",
       "\n",
       "                       conf_tricuspid_regurgitation              wma  conf_wma  \n",
       "L.V. is niet vergroot                      0.877692      wma_present  0.980276  \n",
       "LVH                                        0.673197      wma_present  0.926663  \n",
       "Goede R.V. functie.                        0.509716  wma_not_present  0.664993  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\VENVS\\Envs\\nlp_310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "TEST_RESULTS = {}\n",
    "for k in class_ds.keys():\n",
    "    if k != 'normal':\n",
    "        CATmodel = MetaCAT.load(os.path.join(medcat_path, f'meta_{k}'))\n",
    "        CATmodel.config['train']['score_average'] = 'macro'\n",
    "        test_location = class_ds[k]['test_location']\n",
    "        test_labels = json.load(open(test_location, 'r'))\n",
    "        bulk_res = CATmodel.eval(test_location)\n",
    "        \n",
    "        res_count = defaultdict(int)\n",
    "        for doc in test_labels['projects'][0]['documents']:\n",
    "            anns = doc['annotations']\n",
    "            if len(anns)>0:\n",
    "                for ann in anns:            \n",
    "                    _ann = ann['meta_anns'][k]\n",
    "                    res_count[_ann['value']] += 1\n",
    "\n",
    "        TEST_RESULTS[k] = {\n",
    "            'f1':  bulk_res['f1'],\n",
    "            'precision': bulk_res['precision'],\n",
    "            'recall': bulk_res['recall'],\n",
    "            'confusion_df': bulk_res['confusion matrix'],\n",
    "            'real_presence': res_count\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aortic_regurgitation', 'aortic_stenosis', 'diastolic_dysfunction', 'lv_dil', 'lv_syst_func', 'mitral_regurgitation', 'pe', 'rv_dil', 'rv_syst_func', 'tricuspid_regurgitation', 'wma'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_RESULTS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9744575936883628,\n",
       " 'precision': 0.9769993390614673,\n",
       " 'recall': 0.9720695970695972,\n",
       " 'confusion_df':                            true wma_not_present  true wma_present\n",
       " predicted wma_not_present                    87                 4\n",
       " predicted wma_present                         2               166,\n",
       " 'real_presence': defaultdict(int,\n",
       "             {'wma_not_present': 91, 'wma_present': 168})}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_RESULTS['wma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(TEST_RESULTS, file=open(\"../artifacts/MetaCAT_test_results.pkl\", \"wb\"))\n",
    "#TEST_RESULTS = dill.load(open(\"../artifacts/MetaCAT_test_results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of performance in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_labels_train = get_medcat_json(open(os.path.join(echo_path, 'echo_span_labels', 'merged_labels.jsonl'), 'r'), \n",
    "                                    TRAIN_INPUT_HASH, 'merged')['projects'][0]['documents']\n",
    "\n",
    "merged_labels_test = get_medcat_json(open(os.path.join(echo_path, 'echo_span_labels', 'merged_labels.jsonl'), 'r'), \n",
    "                                    TEST_INPUT_HASH, 'merged')['projects'][0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [03:25<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "comparison_list = []\n",
    "for medcat_doc in tqdm(merged_labels_test):\n",
    "    txt = medcat_doc['text']\n",
    "    parsed_doc = MCATnew(txt)\n",
    "\n",
    "    res = []\n",
    "    start_stop = []\n",
    "    for ent in parsed_doc.ents:\n",
    "        start_stop.append((ent.start_char, ent.end_char))\n",
    "        res.append(create_dict_with_conf(ent))\n",
    "    \n",
    "    medcat_doc['predicted'] = {k:v for k,v in zip(start_stop, res)}\n",
    "    comparison_list.append(medcat_doc)\n",
    "comparison_list_with_annotations_present = [d for d in comparison_list if len(d['annotations'])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [00:00<00:00, 47601.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_pred_list(pred_dict: dict=None):\n",
    "    return [v for k,v in pred_dict.items() if 'conf_' not in k]\n",
    "    \n",
    "span_suggester_comparison_list = []\n",
    "for d in tqdm(comparison_list_with_annotations_present):\n",
    "    anns = d['annotations']\n",
    "    span_cat_list = []\n",
    "    for ann in anns:\n",
    "        span = (ann['start'], ann['end'])\n",
    "        class_val = ann['meta_anns']['merged']['value']\n",
    "        span_cat_list.append((span, class_val))\n",
    "    \n",
    "    pred_list = []\n",
    "    for k, pred in d['predicted'].items():\n",
    "        pred_list.append((k, get_pred_list(pred)))\n",
    "    \n",
    "    span_suggester_comparison_list.append([span_cat_list, pred_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to get the coverage of spans -> a count of all (partially) overlapping spans\n",
    "# We want to get the token overlap of covered spans (Jaccard?)\n",
    "# span overlap count\n",
    "\n",
    "def _tuple_overlap(tL, tR):\n",
    "    # tL: tuple(begin, end)\n",
    "    # tR: tuple(begin, end)\n",
    "    tLrange = set(range(*tL))\n",
    "    tRrange = set(range(*tR))\n",
    "               \n",
    "    InterSection = len(tLrange.intersection(tRrange))\n",
    "    Union = len(tLrange.union(tRrange))\n",
    "    \n",
    "    return InterSection/Union if Union>0 else np.nan\n",
    "\n",
    "def span_overlap_counter(labeled_spans):\n",
    "    # label_spans: list[[list[((begin,end), label)], list[((begin,end), [labels])]]]\n",
    "    OverlapList = []\n",
    "    for span_labs in labeled_spans:\n",
    "        span_set_medcat = set()\n",
    "        span_set_labeled = set()\n",
    "        for lab_span in span_labs[0]:\n",
    "            span_set_labeled.add(lab_span[0])\n",
    "        \n",
    "        for med_span in span_labs[1]:\n",
    "            span_set_medcat.add(med_span[0])\n",
    "        \n",
    "        # check overlap\n",
    "        jaccard_indices = []\n",
    "        for spanLab in span_set_labeled:\n",
    "            _jaccard_indices = []            \n",
    "            for spanMedcat in span_set_medcat:\n",
    "                _jaccard_indices.append(_tuple_overlap(spanLab, spanMedcat))\n",
    "            try:\n",
    "                max_ = max(_jaccard_indices)\n",
    "            except:\n",
    "                max_ = np.nan\n",
    "            jaccard_indices.append(max_)\n",
    "        OverlapList.append(jaccard_indices)\n",
    "    return OverlapList\n",
    "\n",
    "def span_overlap_counter_with_assignment(labeled_spans):\n",
    "    # label_spans: list[[list[((begin,end), label)], list[((begin,end), [labels])]]]\n",
    "    OverlapList = []\n",
    "    for span_labs in labeled_spans:\n",
    "        span_set_medcat = set()\n",
    "        span_dict_labeled = defaultdict(set)\n",
    "        for lab_span in span_labs[0]:\n",
    "            span_dict_labeled[lab_span[1]].add(lab_span[0])\n",
    "        \n",
    "        for med_span in span_labs[1]:\n",
    "            span_set_medcat.add(med_span[0])\n",
    "        \n",
    "        # check overlap\n",
    "        jaccard_indices = defaultdict(list)\n",
    "        for spanClass, spanLabs in span_dict_labeled.items():\n",
    "            for spanLab in spanLabs:                         \n",
    "                _jaccard_indices = []   \n",
    "                for spanMedcat in span_set_medcat:\n",
    "                    _jaccard_indices.append(_tuple_overlap(spanLab, spanMedcat))\n",
    "                try:\n",
    "                    max_ = max(_jaccard_indices)\n",
    "                except:\n",
    "                    max_ = np.nan\n",
    "                jaccard_indices[spanClass].append(max_)\n",
    "        OverlapList.append(jaccard_indices)\n",
    "    return OverlapList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "OverlapJaccardIndices = span_overlap_counter(span_suggester_comparison_list)\n",
    "OverlapJaccardClassIndices = span_overlap_counter_with_assignment(span_suggester_comparison_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "PerClassValueJaccard = defaultdict(list)\n",
    "for d in OverlapJaccardClassIndices:\n",
    "    for k,v in d.items():\n",
    "        PerClassValueJaccard[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassMap = defaultdict(dict)\n",
    "for k, v in class_ds.items():\n",
    "    for lab in v['labels']:\n",
    "        ClassMap[lab] = k\n",
    "ClassMap['normal'] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "PerClassJaccard = defaultdict(list)\n",
    "for cv, v in PerClassValueJaccard.items():\n",
    "    PerClassJaccard[ClassMap[cv]].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean document coverage: nan, with 0.6787009164851803 over all tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bes3\\AppData\\Local\\Temp\\ipykernel_3528\\1556285475.py:1: RuntimeWarning: Mean of empty slice\n",
      "  MeanPerDocument = [np.nanmean(v) for v in OverlapJaccardIndices]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Span overlap per document')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MeanPerDocument = [np.nanmean(v) for v in OverlapJaccardIndices]\n",
    "MeanOverall = np.nanmean([_v for v in OverlapJaccardIndices for _v in v])\n",
    "\n",
    "print(f\"Mean document coverage: {np.mean(MeanPerDocument)}, with {MeanOverall} over all tokens\")\n",
    "\n",
    "plt.hist(MeanPerDocument, bins=50, color='black');\n",
    "plt.title(\"Span overlap per document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'tricuspid_regurgitation', 'mean': 0.5742186400510773},\n",
       " {'class': 'rv_syst_func', 'mean': 0.7643220714162753},\n",
       " {'class': 'lv_syst_func', 'mean': 0.725442260486021},\n",
       " {'class': 'aortic_regurgitation', 'mean': 0.5664092419919264},\n",
       " {'class': 'mitral_regurgitation', 'mean': 0.6506049489112156},\n",
       " {'class': 'aortic_stenosis', 'mean': 0.4801191183820977},\n",
       " {'class': 'lv_dil', 'mean': 0.4622994060566221},\n",
       " {'class': 'rv_dil', 'mean': 0.30486922540091316},\n",
       " {'class': 'normal', 'mean': 0.532194941490294},\n",
       " {'class': 'pe', 'mean': 0.7936107123597836},\n",
       " {'class': 'diastolic_dysfunction', 'mean': 0.8023843251543331},\n",
       " {'class': 'wma', 'mean': 0.5501622715158951}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'class': k, 'mean': np.nanmean(v)} for k,v in PerClassJaccard.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMean = 0.25\n",
    "CheckRes = [{'Jaccard': v, \n",
    "             'res': comparison_list_with_annotations_present[i]} \n",
    "            for i,v in enumerate(OverlapJaccardIndices)\n",
    "            if (np.mean(v)<MinMean) | (np.isnan(np.mean(v)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 42 documents to check\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(CheckRes)} documents to check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(39,\n",
       "  63): {'aortic_regurgitation': 'aortic_valve_native_regurgitation_not_present', 'conf_aortic_regurgitation': 0.9999958276748657, 'aortic_stenosis': 'aortic_valve_native_stenosis_not_present', 'conf_aortic_stenosis': 0.9999805688858032, 'diastolic_dysfunction': 'lv_dias_func_normal', 'conf_diastolic_dysfunction': 0.9995680451393127, 'lv_dil': 'lv_dil_normal', 'conf_lv_dil': 0.9998514652252197, 'lv_syst_func': 'lv_sys_func_normal', 'conf_lv_syst_func': 0.9994962215423584, 'mitral_regurgitation': 'mitral_valve_native_regurgitation_not_present', 'conf_mitral_regurgitation': 0.9999899864196777, 'Negation': 'not negated', 'conf_Negation': 0.9992412328720093, 'pe': 'pe_not_present', 'conf_pe': 0.999327540397644, 'rv_dil': 'rv_dil_normal', 'conf_rv_dil': 0.9999010562896729, 'rv_syst_func': 'rv_sys_func_normal', 'conf_rv_syst_func': 0.9978834986686707, 'tricuspid_regurgitation': 'tricuspid_valve_native_regurgitation_not_present', 'conf_tricuspid_regurgitation': 0.9991766810417175, 'wma': 'wma_not_present', 'conf_wma': 0.9994674324989319},\n",
       " (255,\n",
       "  262): {'aortic_regurgitation': 'aortic_valve_native_regurgitation_not_present', 'conf_aortic_regurgitation': 0.9997890591621399, 'aortic_stenosis': 'aortic_valve_native_stenosis_not_present', 'conf_aortic_stenosis': 0.9997469782829285, 'diastolic_dysfunction': 'lv_dias_func_normal', 'conf_diastolic_dysfunction': 0.9838551878929138, 'lv_dil': 'lv_dil_normal', 'conf_lv_dil': 0.9987841248512268, 'lv_syst_func': 'lv_sys_func_unknown', 'conf_lv_syst_func': 0.4336005449295044, 'mitral_regurgitation': 'mitral_valve_native_regurgitation_not_present', 'conf_mitral_regurgitation': 0.9998015761375427, 'Negation': 'not negated', 'conf_Negation': 0.9997686743736267, 'pe': 'pe', 'conf_pe': 0.9976733326911926, 'rv_dil': 'rv_dil_normal', 'conf_rv_dil': 0.9917722344398499, 'rv_syst_func': 'rv_syst_func_normal', 'conf_rv_syst_func': 0.9963184595108032, 'tricuspid_regurgitation': 'tricuspid_valve_native_regurgitation_not_present', 'conf_tricuspid_regurgitation': 0.8833280801773071, 'wma': 'wma_present', 'conf_wma': 0.9925798773765564},\n",
       " (290,\n",
       "  294): {'aortic_regurgitation': 'aortic_valve_native_regurgitation_not_present', 'conf_aortic_regurgitation': 0.9993415474891663, 'aortic_stenosis': 'aortic_valve_native_stenosis_not_present', 'conf_aortic_stenosis': 0.9763898849487305, 'diastolic_dysfunction': 'lv_dias_func_normal', 'conf_diastolic_dysfunction': 0.9241250157356262, 'lv_dil': 'lv_dil_normal', 'conf_lv_dil': 0.9991006851196289, 'lv_syst_func': 'lv_sys_func_unknown', 'conf_lv_syst_func': 0.7922925353050232, 'mitral_regurgitation': 'mitral_valve_native_regurgitation_not_present', 'conf_mitral_regurgitation': 0.9983760118484497, 'Negation': 'not negated', 'conf_Negation': 0.9998291730880737, 'pe': 'pe_not_present', 'conf_pe': 0.7197046279907227, 'rv_dil': 'rv_dil_normal', 'conf_rv_dil': 0.9910303354263306, 'rv_syst_func': 'rv_syst_func_normal', 'conf_rv_syst_func': 0.9996705055236816, 'tricuspid_regurgitation': 'tricuspid_valve_native_regurgitation_trace', 'conf_tricuspid_regurgitation': 0.8379576206207275, 'wma': 'wma_not_present', 'conf_wma': 0.8728786110877991},\n",
       " (354,\n",
       "  357): {'aortic_regurgitation': 'aortic_valve_native_regurgitation_not_present', 'conf_aortic_regurgitation': 0.9999834299087524, 'aortic_stenosis': 'aortic_valve_native_stenosis_not_present', 'conf_aortic_stenosis': 0.9674327969551086, 'diastolic_dysfunction': 'lv_dias_func_severe', 'conf_diastolic_dysfunction': 0.6429408192634583, 'lv_dil': 'lv_dil_normal', 'conf_lv_dil': 0.986152172088623, 'lv_syst_func': 'lv_sys_func_unknown', 'conf_lv_syst_func': 0.38940680027008057, 'mitral_regurgitation': 'mitral_valve_native_regurgitation_severe', 'conf_mitral_regurgitation': 0.8832756280899048, 'Negation': 'not negated', 'conf_Negation': 0.9999743700027466, 'pe': 'pe_not_present', 'conf_pe': 0.9789693355560303, 'rv_dil': 'rv_dil_normal', 'conf_rv_dil': 0.9893144369125366, 'rv_syst_func': 'rv_syst_func_normal', 'conf_rv_syst_func': 0.9891546368598938, 'tricuspid_regurgitation': 'tricuspid_valve_native_regurgitation_not_present', 'conf_tricuspid_regurgitation': 0.8428921103477478, 'wma': 'wma_present', 'conf_wma': 0.9962083101272583}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CheckRes[0]['res']['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check maximum length of the spans detected with MedCAT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nlp_310)",
   "language": "python",
   "name": "python3_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "01a14be5a308536305ca6f1be76534a0246168409855a6497a1510fcfd428ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
