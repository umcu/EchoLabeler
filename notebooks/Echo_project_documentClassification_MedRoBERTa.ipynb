{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:03.484607Z",
     "start_time": "2024-04-25T15:38:35.109090Z"
    }
   },
   "outputs": [],
   "source": [
    "# add autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from typing import List, Tuple, Dict, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bes3\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\echolabeler-DyKQcQCO-py3.10\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "import benedict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA RTX 4000 Ada Generation\n",
      "Memory Allocated: 0\n",
      "Max memory Allocated: 0\n",
      "Memory reserved: 0\n",
      "Max memory reserved: 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated()}\")\n",
    "    print(f\"Max memory Allocated: {torch.cuda.max_memory_allocated()}\") \n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved()}\")\n",
    "    print(f\"Max memory reserved: {torch.cuda.max_memory_reserved()}\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deabbreviate = False\n",
    "filter_reports = True\n",
    "Class = 'rv_syst_func' # lv_dil, rv_dil, pe, aortic_regurgitation, diastolic_dysfunction, lv_syst_func, aortic_stenosis, rv_syst_func, mitral_regurgitation,tricuspid_regurgitation,wma\n",
    "FLAG_TERMS = ['uitslag zie medische status', 'zie status', 'zie verslag status', 'slecht echovenster', 'echo overwegen', 'ge echo',\n",
    "              'geen echovenster', 'geen beoordeelbaar echo', 'geen beoordeelbare echo', 'verslag op ic']\n",
    "SAVE_TERMS = ['goed', 'geen', 'normaal', 'normale']\n",
    "use_multilabel = False\n",
    "reduce_labels = True\n",
    "num_epochs = 5\n",
    "\n",
    "MULTILABELS = {'Mild': ['Mild', 'Present'], \n",
    "               'Severe': ['Severe', 'Present'],\n",
    "               'Moderate': ['Moderate', 'Present'],\n",
    "               'Normal': ['Normal'],\n",
    "               'No label': ['No label'],\n",
    "               'Present': ['Present'],\n",
    "               }\n",
    "\n",
    "Target_remapper = {'No label': 'No label', \n",
    "                   'Normal': 'Normal',\n",
    "                   'Mild': 'Not normal',\n",
    "                   'Moderate': 'Not normal',\n",
    "                   'Severe': 'Not normal',\n",
    "                   'Present':  'Not normal'\n",
    "                   }\n",
    "\n",
    "\n",
    "#Target_remapper = {'No label': 'Normal', \n",
    "#                   'Normal': 'Normal',\n",
    "#                   'Mild': 'Not normal',\n",
    "#                   'Moderate': 'Not normal',\n",
    "#                   'Severe': 'Not normal',\n",
    "#                   'Present':  'Not normal'\n",
    "#                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the src folder to the path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "import deabber, echo_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if deabbreviate:\n",
    "    ABBREVIATIONS = benedict.benedict(\"../assets/abbreviations.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:03.996106Z",
     "start_time": "2024-04-25T15:39:03.489109Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "def plot_history(history, val=0):\n",
    "    acc = history.history['accuracy']\n",
    "    if val == 1:\n",
    "        val_acc = history.history['val_accuracy'] # we can add a validation set in our fit function with nn\n",
    "    loss = history.history['loss']\n",
    "    if val == 1:\n",
    "        val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:04.476606Z",
     "start_time": "2024-04-25T15:39:03.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_binomial(logits_and_labels, averaging='macro'):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions, average = averaging)\n",
    "  prec = precision_score(labels, predictions, average = averaging)\n",
    "  rec = recall_score(labels, predictions, average = averaging)\n",
    "  return {\n",
    "          'accuracy': acc, \n",
    "          'f1_score': f1,\n",
    "          'precision': prec,\n",
    "          'recal': rec\n",
    "          }\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    \n",
    "    \n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    prec_macro = precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    prec_weighted = precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    recall_macro = recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    recall_weighted = recall_score(y_true=y_true, y_pred=y_pred, average='weighted')    \n",
    "    \n",
    "    try:\n",
    "        roc_auc_weighted = roc_auc_score(y_true, probs, average = 'weighted')\n",
    "        roc_auc_macro = roc_auc_score(y_true, probs, average = 'macro')\n",
    "    except:\n",
    "        roc_auc_weighted = None\n",
    "        roc_auc_macro = None\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1_macro': f1_macro,\n",
    "               'f1_weighted': f1_weighted,\n",
    "               'prec_macro': prec_macro,\n",
    "               'prec_weighted': prec_weighted,\n",
    "               'recall_macro': recall_macro,\n",
    "               'recall_weighted': recall_weighted,\n",
    "               'roc_auc_macro': roc_auc_macro,\n",
    "               'roc_auc_weighted': roc_auc_weighted,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:05.003636Z",
     "start_time": "2024-04-25T15:39:04.479108Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # labels should be a list or a 1D tensor\n",
    "    one_hot = torch.zeros((len(labels), num_classes))\n",
    "    rows = torch.arange(len(labels))\n",
    "    one_hot[rows, labels] = 1\n",
    "    return one_hot\n",
    "\n",
    "def _mlabel_tuple_creator(x: List[int],\n",
    "                          multilabels:Dict[int,List[int]],\n",
    "                          num_classes: int=None)\\\n",
    "                          ->List[Tuple[int,...]]:\n",
    "                              \n",
    "    res = [(_sc for _sc in multilabels[sc]) for sc in x]\n",
    "    return res\n",
    "\n",
    "def multi_hot_encoding(x: List[int], \n",
    "                       multilabels: Union[Dict[int,List[int]], None]=None,\n",
    "                       num_classes: int=None)\\\n",
    "                           ->torch.Tensor:    \n",
    "    if multilabels is None:\n",
    "        return one_hot_encode(x, num_classes=num_classes)\n",
    "    else:\n",
    "        return torch.Tensor(MultiLabelBinarizer(classes=range(num_classes))\\\n",
    "                    .fit_transform(_mlabel_tuple_creator(x,multilabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:06.259117Z",
     "start_time": "2024-04-25T15:39:05.008110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bes3\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\echolabeler-DyKQcQCO-py3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"CLTL/MedRoBERTa.nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:07.328611Z",
     "start_time": "2024-04-25T15:39:06.261613Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('T://lab_research/RES-Folder-UPOD/Echo_label/E_ResearchData/2_ResearchData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:08.119113Z",
     "start_time": "2024-04-25T15:39:07.331615Z"
    }
   },
   "outputs": [],
   "source": [
    "labeled_documents = pd.read_json(f\"./echo_doc_labels/{Class}.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "No label    2538\n",
       "Normal      1807\n",
       "Mild         408\n",
       "Moderate     188\n",
       "Severe        59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_documents.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "No label      2538\n",
      "Normal        1807\n",
      "Not normal     655\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Target_remapper = {'No label': 'No label', \n",
    "                   'Normal': 'Normal',\n",
    "                   'Mild': 'Not normal',\n",
    "                   'Moderate': 'Not normal',\n",
    "                   'Severe': 'Not normal',\n",
    "                   'Present': 'Not normal'\n",
    "                   }\n",
    "if reduce_labels:\n",
    "    labeled_documents['label'] = labeled_documents.label.map(Target_remapper)\n",
    "    print(labeled_documents.label.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>_input_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goede functie van R.V. en L.V. Nog bekijken me...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-1492643194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goede L.V. functie en R.V. functie. Er is een ...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-1268308324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normale dimensie LV. prominent basale septum, ...</td>\n",
       "      <td>No label</td>\n",
       "      <td>-1752879130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Globaal redelijke systolische restfunctie. Voo...</td>\n",
       "      <td>No label</td>\n",
       "      <td>-1692751703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goede systolische LV-functie. Matige cLVH. Gee...</td>\n",
       "      <td>No label</td>\n",
       "      <td>570163096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>De beperkte echovensters suggereren goede LV e...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1186042732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>TEE tape 191\\r\\nOnder 1 % lidocaine vlotte int...</td>\n",
       "      <td>No label</td>\n",
       "      <td>-478911984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Technisch moeizaam echo.\\r\\n- De L.V. is niet ...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>963390338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Matig echo window.\\r\\nNiet gedilateerde LV met...</td>\n",
       "      <td>No label</td>\n",
       "      <td>-1897706486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Billowing van de mitralisklep, licht verdikte ...</td>\n",
       "      <td>No label</td>\n",
       "      <td>675186527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label  _input_hash\n",
       "0     Goede functie van R.V. en L.V. Nog bekijken me...    Normal  -1492643194\n",
       "1     Goede L.V. functie en R.V. functie. Er is een ...    Normal  -1268308324\n",
       "2     Normale dimensie LV. prominent basale septum, ...  No label  -1752879130\n",
       "3     Globaal redelijke systolische restfunctie. Voo...  No label  -1692751703\n",
       "4     Goede systolische LV-functie. Matige cLVH. Gee...  No label    570163096\n",
       "...                                                 ...       ...          ...\n",
       "4995  De beperkte echovensters suggereren goede LV e...    Normal   1186042732\n",
       "4996  TEE tape 191\\r\\nOnder 1 % lidocaine vlotte int...  No label   -478911984\n",
       "4997  Technisch moeizaam echo.\\r\\n- De L.V. is niet ...    Normal    963390338\n",
       "4998  Matig echo window.\\r\\nNiet gedilateerde LV met...  No label  -1897706486\n",
       "4999  Billowing van de mitralisklep, licht verdikte ...  No label    675186527\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:09.049113Z",
     "start_time": "2024-04-25T15:39:08.571112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Expand with label columns\n",
    "Target_maps = {Label:i for i,Label in enumerate(labeled_documents['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'No label': 1, 'Not normal': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:10.056612Z",
     "start_time": "2024-04-25T15:39:09.051621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ECHO_StudyID', 'ECHO_StudyID.1', 'input_hash', 'task_hash'], dtype='object')\n",
      "Train hashes: 96026\n",
      "Test hashes: 24051\n"
     ]
    }
   ],
   "source": [
    "# Load the train/test hashes\n",
    "test_hashes = pd.read_csv('./test_echoid.csv', sep=',')\n",
    "train_hashes = pd.read_csv('./train_echoid.csv', sep=',')\n",
    "print(train_hashes.columns)\n",
    "\n",
    "print(f\"Train hashes: {train_hashes.input_hash.nunique()}\")\n",
    "print(f\"Test hashes: {test_hashes.input_hash.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Normal', 'No label', 'Not normal'])\n"
     ]
    }
   ],
   "source": [
    "print(Target_maps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:14.753116Z",
     "start_time": "2024-04-25T15:39:10.601615Z"
    }
   },
   "outputs": [],
   "source": [
    "# We now make DataSets (a special HuggingFace structure)\n",
    "# assuming cross-validation\n",
    "\n",
    "DF = labeled_documents\n",
    "DF.columns = ['sentence', 'labels', '_input_hash']\n",
    "\n",
    "label2id = Target_maps\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "num_labels = len(label2id)\n",
    "DF['labels'] = DF['labels'].map(label2id)\n",
    "\n",
    "\n",
    "if filter_reports:\n",
    "    DF = DF.assign(sentence = echo_utils.report_filter(DF.sentence, \n",
    "                                            flag_terms=FLAG_TERMS, \n",
    "                                            save_terms=SAVE_TERMS)[0])\n",
    "    DF = DF.loc[DF.sentence.notna()]\n",
    "\n",
    "if deabbreviate:\n",
    "    DeAbber = deabber.deabber(model_type='sbert', \n",
    "                              abbreviations=ABBREVIATIONS['nl']['echocardiogram'], \n",
    "                              min_sim=0.5, top_k=10)\n",
    "    DF = DF.assign(sentence=DeAbber.deabb(DF.sentence.values, TokenRadius=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_multilabel:\n",
    "    _multilabels = {label2id[k]: [label2id[l] for l in v]\n",
    "                    for k,v in MULTILABELS.items()}\n",
    "else:\n",
    "    _multilabels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:\n",
      "labels\n",
      "1    1958\n",
      "0    1431\n",
      "2     520\n",
      "Name: count, dtype: int64\n",
      "Test labels:\n",
      "labels\n",
      "1    497\n",
      "0    342\n",
      "2    119\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87d6e9a0d76428ab72c2160aa1aa512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3909 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be03f2925540ceb4ee9fe186077d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# TODO: make proper\n",
    "DFtrain = DF.loc[DF._input_hash.isin(train_hashes.input_hash), ['sentence', 'labels']]\n",
    "DFtest = DF.loc[DF._input_hash.isin(test_hashes.input_hash), ['sentence', 'labels']]\n",
    "\n",
    "print(\"Train labels:\")\n",
    "print(DFtrain.labels.value_counts())\n",
    "print(\"Test labels:\")\n",
    "print(DFtest.labels.value_counts())\n",
    "\n",
    "TrainSet = Dataset.from_pandas(DFtrain)\n",
    "TestSet = Dataset.from_pandas(DFtest)\n",
    "\n",
    "HF_DataSet = DatasetDict(\n",
    "    {'train' : TrainSet,\n",
    "     'test': TestSet,\n",
    "    }\n",
    ")\n",
    "\n",
    "Tokenized_DataSet = HF_DataSet.map(lambda batch: tokenizer(batch, truncation=True, \n",
    "                                                                  padding=True, \n",
    "                                                                  max_length=256),\n",
    "                                  input_columns='sentence',\n",
    "                                  batched=True,\n",
    "                                  remove_columns=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9752e9d8a44a3dac8b0abe547e924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3909 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be3bbb55f664e85a873764d86ffa693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tokenized_DataSet = (Tokenized_DataSet\n",
    "                      #.map(lambda x : {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"])\n",
    "                      .map(lambda x: {\"labels\": \n",
    "                          multi_hot_encoding(x['labels'], \n",
    "                                             multilabels=_multilabels, \n",
    "                                             num_classes=num_labels)}, \n",
    "                           batched=True, remove_columns=['labels']))                      \n",
    "                      #.rename_column(\"float_labels\", \"labels\"))\n",
    "\n",
    "Tokenized_DataSet.set_format(\"torch\", \n",
    "                             columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:15.961514Z",
     "start_time": "2024-04-25T15:39:14.755619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bes3\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\echolabeler-DyKQcQCO-py3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at CLTL/MedRoBERTa.nl and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/drive/1aue7x525rKy6yYLqqt-5Ll96qjQvpqS7#scrollTo=1eVCRpcLUW-y\n",
    "# https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
    "medroberta_clf = AutoModelForSequenceClassification.from_pretrained(\"CLTL/MedRoBERTa.nl\", \n",
    "                                                num_labels=len(id2label.keys()),\n",
    "                                                problem_type='multi_label_classification',\n",
    "                                                id2label=id2label,\n",
    "                                                label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:16.442038Z",
     "start_time": "2024-04-25T15:39:15.968514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "RobertaForSequenceClassification                             --\n",
       "├─RobertaModel: 1-1                                          --\n",
       "│    └─RobertaEmbeddings: 2-1                                --\n",
       "│    │    └─Embedding: 3-1                                   39,936,000\n",
       "│    │    └─Embedding: 3-2                                   394,752\n",
       "│    │    └─Embedding: 3-3                                   768\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─RobertaEncoder: 2-2                                   --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "├─RobertaClassificationHead: 1-2                             --\n",
       "│    └─Linear: 2-3                                           590,592\n",
       "│    └─Dropout: 2-4                                          --\n",
       "│    └─Linear: 2-5                                           2,307\n",
       "=====================================================================================\n",
       "Total params: 125,980,419\n",
       "Trainable params: 125,980,419\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(medroberta_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MedRoBERTa.nl -- Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:17.139141Z",
     "start_time": "2024-04-25T15:39:16.445015Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = \"T:\\\\laupodteam/AIOS/Bram/data/tmp\"\n",
    "metric_name = 'f1_macro'\n",
    "training_args = TrainingArguments(output_dir=train_dir,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  save_strategy='epoch',\n",
    "                                  num_train_epochs=num_epochs,\n",
    "                                  learning_rate=5e-5,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  weight_decay=0.01,\n",
    "                                  per_device_eval_batch_size=10,\n",
    "                                  load_best_model_at_end=True, \n",
    "                                  metric_for_best_model=metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:39:17.650625Z",
     "start_time": "2024-04-25T15:39:17.141604Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(medroberta_clf,\n",
    "                  training_args,\n",
    "                  train_dataset = Tokenized_DataSet[\"train\"],\n",
    "                  eval_dataset = Tokenized_DataSet[\"test\"],\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=data_collator,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MedRoBERTa.nl -- run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5f9bfaf54d456090084b09692221b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1225823a5c7d467d8f3110b75674c699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10540775954723358, 'eval_f1_macro': 0.9134137229403607, 'eval_f1_weighted': 0.9526689509950355, 'eval_prec_macro': 0.9406026561568023, 'eval_prec_weighted': 0.9536079685744389, 'eval_recall_macro': 0.8907472503835029, 'eval_recall_weighted': 0.9530271398747391, 'eval_roc_auc_macro': 0.9840262113286249, 'eval_roc_auc_weighted': 0.9858562572623008, 'eval_accuracy': 0.9498956158663883, 'eval_runtime': 4.8372, 'eval_samples_per_second': 198.049, 'eval_steps_per_second': 19.846, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca917715752e4247a52f9bc7947ee98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09395516663789749, 'eval_f1_macro': 0.914843517480219, 'eval_f1_weighted': 0.9542215876731077, 'eval_prec_macro': 0.9117272157605955, 'eval_prec_weighted': 0.9594256835350793, 'eval_recall_macro': 0.9206477943632154, 'eval_recall_weighted': 0.9498956158663883, 'eval_roc_auc_macro': 0.9909293049109262, 'eval_roc_auc_weighted': 0.9899882726030039, 'eval_accuracy': 0.9498956158663883, 'eval_runtime': 4.9374, 'eval_samples_per_second': 194.029, 'eval_steps_per_second': 19.443, 'epoch': 2.0}\n",
      "{'loss': 0.1413, 'grad_norm': 0.262879341840744, 'learning_rate': 2.959183673469388e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1411c1aedec4aa5882f01b08c29e757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08383443206548691, 'eval_f1_macro': 0.9434414021223455, 'eval_f1_weighted': 0.9681142036551459, 'eval_prec_macro': 0.9469638259043524, 'eval_prec_weighted': 0.9697215685474252, 'eval_recall_macro': 0.940200610208252, 'eval_recall_weighted': 0.9665970772442589, 'eval_roc_auc_macro': 0.9943955990688425, 'eval_roc_auc_weighted': 0.993799129881617, 'eval_accuracy': 0.9665970772442589, 'eval_runtime': 4.8567, 'eval_samples_per_second': 197.254, 'eval_steps_per_second': 19.767, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2a244cdaca43ee91401138fa6d78ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08312099426984787, 'eval_f1_macro': 0.9498360507329767, 'eval_f1_weighted': 0.9727502877264206, 'eval_prec_macro': 0.9549569829921004, 'eval_prec_weighted': 0.9726893998375026, 'eval_recall_macro': 0.9448446459603422, 'eval_recall_weighted': 0.9728601252609603, 'eval_roc_auc_macro': 0.994079687176257, 'eval_roc_auc_weighted': 0.9936515243707174, 'eval_accuracy': 0.9728601252609603, 'eval_runtime': 4.8876, 'eval_samples_per_second': 196.005, 'eval_steps_per_second': 19.641, 'epoch': 4.0}\n",
      "{'loss': 0.0223, 'grad_norm': 8.819168090820312, 'learning_rate': 9.183673469387756e-06, 'epoch': 4.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dece02a00f2648ee8b189ff8d45d6917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08433438837528229, 'eval_f1_macro': 0.9516461020337991, 'eval_f1_weighted': 0.973193956443554, 'eval_prec_macro': 0.9605577175051468, 'eval_prec_weighted': 0.9736628085266955, 'eval_recall_macro': 0.9430809290109305, 'eval_recall_weighted': 0.9728601252609603, 'eval_roc_auc_macro': 0.994129173466613, 'eval_roc_auc_weighted': 0.9935770726766903, 'eval_accuracy': 0.9718162839248434, 'eval_runtime': 4.9123, 'eval_samples_per_second': 195.021, 'eval_steps_per_second': 19.543, 'epoch': 5.0}\n",
      "{'train_runtime': 494.4517, 'train_samples_per_second': 39.529, 'train_steps_per_second': 2.477, 'train_loss': 0.06798359335685263, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1225, training_loss=0.06798359335685263, metrics={'train_runtime': 494.4517, 'train_samples_per_second': 39.529, 'train_steps_per_second': 2.477, 'total_flos': 2571275874746880.0, 'train_loss': 0.06798359335685263, 'epoch': 5.0})"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15d817771e44a3ca1027a948d9743da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08433438837528229,\n",
       " 'eval_f1_macro': 0.9516461020337991,\n",
       " 'eval_f1_weighted': 0.973193956443554,\n",
       " 'eval_prec_macro': 0.9605577175051468,\n",
       " 'eval_prec_weighted': 0.9736628085266955,\n",
       " 'eval_recall_macro': 0.9430809290109305,\n",
       " 'eval_recall_weighted': 0.9728601252609603,\n",
       " 'eval_roc_auc_macro': 0.994129173466613,\n",
       " 'eval_roc_auc_weighted': 0.9935770726766903,\n",
       " 'eval_accuracy': 0.9718162839248434,\n",
       " 'eval_runtime': 5.0331,\n",
       " 'eval_samples_per_second': 190.338,\n",
       " 'eval_steps_per_second': 19.074,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_dataset = Tokenized_DataSet[\"test\"]\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T19:31:44.706606Z",
     "start_time": "2024-04-25T19:31:44.706095Z"
    }
   },
   "outputs": [],
   "source": [
    "#medroberta_clf_pipe = pipeline('text-classification', model=medroberta_clf, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current directory of .py file, i.e. NOT os.getcwd()\n",
    "#os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
