{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# All classes\n",
    "## Simple general: multinomial\n",
    "MedRoBERTa.nl – {“Normal_or_no_label”: Normal or no label for all classes,\n",
    "                 “Present”: any non-normal present}\n",
    " \n",
    "## Bespoke general: multilabel\n",
    "MedRoBERTa.nl – {“Normal_or_no_label”: Normal or no label for all classes, \n",
    "                 “aortic_regurgitation_present”: ..,\n",
    "                 “aortic_stenosis_present”: ..\n",
    "                  …\n",
    "                }\n",
    "                 \n",
    "# Per class, i.e. 11 models -- DONE\n",
    "MedRoBERTa.nl – {“no label”: ..\n",
    "                 “mild”: ..\n",
    "                 “moderate”: ..\n",
    "                 “severe”: ..\n",
    "                “present”: ..}\n",
    " \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.483230Z",
     "start_time": "2024-07-31T12:17:51.451900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from torchinfo import summary\n",
    "\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.655027Z",
     "start_time": "2024-07-31T12:17:51.623773Z"
    }
   },
   "source": [
    "import torch"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.702314Z",
     "start_time": "2024-07-31T12:17:51.676093Z"
    }
   },
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "import benedict\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.764416Z",
     "start_time": "2024-07-31T12:17:51.739175Z"
    }
   },
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.795621Z",
     "start_time": "2024-07-31T12:17:51.764416Z"
    }
   },
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated()}\")\n",
    "    print(f\"Max memory Allocated: {torch.cuda.max_memory_allocated()}\") \n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved()}\")\n",
    "    print(f\"Max memory reserved: {torch.cuda.max_memory_reserved()}\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA RTX 4000 Ada Generation\n",
      "Memory Allocated: 1579976192\n",
      "Max memory Allocated: 7143088128\n",
      "Memory reserved: 5200936960\n",
      "Max memory reserved: 7530872832\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.842430Z",
     "start_time": "2024-07-31T12:17:51.826875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "possible_classes = [\"aortic_regurgitation\", \"aortic_stenosis\", \"diastolic_dysfunction\", \"tricuspid_regurgitation\", \"wma\",\n",
    "                    \"lv_dil\", \"lv_syst_func\", \"mitral_regurgitation\", \"pe\", \"rv_dil\", \"rv_syst_func\"]"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.873793Z",
     "start_time": "2024-07-31T12:17:51.842430Z"
    }
   },
   "source": [
    "deabbreviate = False\n",
    "filter_reports = True\n",
    "Classes = ['mitral_regurgitation','tricuspid_regurgitation', 'wma'] # 'aortic_regurgitation'\n",
    "FLAG_TERMS = ['uitslag zie medische status', 'zie status', 'zie verslag status', 'slecht echovenster', 'echo overwegen', 'ge echo',\n",
    "              'geen echovenster', 'geen beoordeelbaar echo', 'tee 190', 'hdf 36mnd', 'geen beoordeelbare echo', 'verslag op ic', 'psyheartanalyse']\n",
    "SAVE_TERMS = ['goed', 'geen', 'normaal', 'normale']\n",
    "use_multilabel = False\n",
    "reduce_labels = True\n",
    "num_epochs = 10\n",
    "uni_model = True\n",
    "uni_model_simple = False\n",
    "\n",
    "\n",
    "use_multilabel = True if (uni_model) & (~uni_model_simple) else False\n",
    "\n",
    "MULTILABELS = {'Mild': ['Mild', 'Present'], \n",
    "               'Severe': ['Severe', 'Present'],\n",
    "               'Moderate': ['Moderate', 'Present'],\n",
    "               'Normal': ['Normal'],\n",
    "               'No label': ['No label'],\n",
    "               'Present': ['Present'],\n",
    "               }\n",
    "Target_remapper = {'No label': 'No label', \n",
    "                   'Normal': 'Normal',\n",
    "                   'Mild': 'Not normal',\n",
    "                   'Moderate': 'Not normal',\n",
    "                   'Severe': 'Not normal',\n",
    "                   'Present': 'Not normal'\n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "#Target_remapper = {'No label': 'Normal', \n",
    "#                   'Normal': 'Normal',\n",
    "#                   'Mild': 'Not normal',\n",
    "#                   'Moderate': 'Not normal',\n",
    "#                   'Severe': 'Not normal',\n",
    "#                   'Present':  'Not normal'\n",
    "#                   }\n",
    "\n",
    "# train a MedRoBERTa.nl model that trains on\n",
    "# No label: whether there is \"no label\" for all classes\n",
    "# Normal: whether all the classes are normal\n",
    "# Present: \n"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.889481Z",
     "start_time": "2024-07-31T12:17:51.873793Z"
    }
   },
   "source": [
    "#Add the src folder to the path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "import deabber, echo_utils"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:51.951923Z",
     "start_time": "2024-07-31T12:17:51.920685Z"
    }
   },
   "source": [
    "if deabbreviate:\n",
    "    ABBREVIATIONS = benedict.benedict(\"../assets/abbreviations.yml\")"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.014414Z",
     "start_time": "2024-07-31T12:17:51.983179Z"
    }
   },
   "source": [
    "plt.style.use('ggplot')\n",
    "def plot_history(history, val=0):\n",
    "    acc = history.history['accuracy']\n",
    "    if val == 1:\n",
    "        val_acc = history.history['val_accuracy'] # we can add a validation set in our fit function with nn\n",
    "    loss = history.history['loss']\n",
    "    if val == 1:\n",
    "        val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.061555Z",
     "start_time": "2024-07-31T12:17:52.029962Z"
    }
   },
   "source": [
    "def compute_metrics_binomial(logits_and_labels, averaging='macro'):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions, average = averaging)\n",
    "  prec = precision_score(labels, predictions, average = averaging)\n",
    "  rec = recall_score(labels, predictions, average = averaging)\n",
    "  return {\n",
    "          'accuracy': acc, \n",
    "          'f1_score': f1,\n",
    "          'precision': prec,\n",
    "          'recal': rec\n",
    "          }\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    \n",
    "    \n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "    f1_list = f1_score(y_true=y_true, y_pred=y_pred, average=None, zero_division=0)\n",
    "    prec_macro = precision_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "    prec_weighted = precision_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "    prec_list = precision_score(y_true=y_true, y_pred=y_pred, average=None, zero_division=0)\n",
    "    recall_macro = recall_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "    recall_list = recall_score(y_true=y_true, y_pred=y_pred, average=None, zero_division=0)  \n",
    "    \n",
    "    try:\n",
    "        roc_auc_weighted = roc_auc_score(y_true, probs, average = 'weighted')\n",
    "        roc_auc_macro = roc_auc_score(y_true, probs, average = 'macro')\n",
    "        roc_auc_list = roc_auc_score(y_true, probs, average = None)\n",
    "    except:\n",
    "        roc_auc_weighted = None\n",
    "        roc_auc_macro = None\n",
    "        roc_auc_list = []\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1_macro': f1_macro,\n",
    "               'f1_weighted': f1_weighted,\n",
    "               'prec_weighted': prec_weighted,\n",
    "               'prec_macro': prec_macro,\n",
    "               'recall_macro': recall_macro,\n",
    "               'recall_weighted': recall_weighted,\n",
    "               'roc_auc_macro': roc_auc_macro,\n",
    "               'roc_auc_weighted': roc_auc_weighted,\n",
    "               'accuracy': accuracy}\n",
    "    \n",
    "    for k, _f1 in enumerate(f1_list):\n",
    "        metrics[f'f1_{k}'] = _f1\n",
    "    for k, _prec in enumerate(prec_list):\n",
    "        metrics[f'prec_{k}'] = _prec\n",
    "    for k, _recall in enumerate(recall_list):\n",
    "        metrics[f'recall_{k}'] = _recall\n",
    "    for k, _auc in enumerate(roc_auc_list):\n",
    "        metrics[f'auc_{k}'] = _auc\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result\n",
    "     \n"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.092779Z",
     "start_time": "2024-07-31T12:17:52.061555Z"
    }
   },
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # labels should be a list or a 1D tensor\n",
    "    one_hot = torch.zeros((len(labels), num_classes))\n",
    "    rows = torch.arange(len(labels))\n",
    "    one_hot[rows, labels] = 1\n",
    "    return one_hot\n",
    "\n",
    "def _mlabel_tuple_creator(x: List[int],\n",
    "                          multilabels:Dict[int,List[int]],\n",
    "                          num_classes: int=None)\\\n",
    "                          ->List[Tuple[int,...]]:\n",
    "                              \n",
    "    res = [(_sc for _sc in multilabels[sc]) for sc in x]\n",
    "    return res\n",
    "\n",
    "def multi_hot_encoding(x: List[int], \n",
    "                       multilabels: Union[Dict[int,List[int]], None]=None,\n",
    "                       num_classes: int=None)\\\n",
    "                           ->torch.Tensor:    \n",
    "    if multilabels is None:\n",
    "        return one_hot_encode(x, num_classes=num_classes)\n",
    "    else:\n",
    "        return torch.Tensor(MultiLabelBinarizer(classes=range(num_classes))\\\n",
    "                    .fit_transform(_mlabel_tuple_creator(x,multilabels)))"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.779903Z",
     "start_time": "2024-07-31T12:17:52.124015Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"CLTL/MedRoBERTa.nl\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bes3\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\echolabeler-DyKQcQCO-py3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.803808Z",
     "start_time": "2024-07-31T12:17:52.779903Z"
    }
   },
   "source": [
    "os.chdir('T://lab_research/RES-Folder-UPOD/Echo_label/E_ResearchData/2_ResearchData')"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.826945Z",
     "start_time": "2024-07-31T12:17:52.803808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lab_dict_parser_simple(x: dict=None):       \n",
    "    # if any of the values is not in ['Normal', 'No_label'] return 'Present'\n",
    "    if any([v not in ['Normal', 'No_label'] for v in x.values()]):\n",
    "        return 'Present'     \n",
    "    return 'Normal_or_No_Label'\n",
    "\n",
    "def lab_dict_parser_bespoke(x: dict=None):       \n",
    "    # if any of the values is not in ['Normal', 'No_label'] return 'Present'\n",
    "    if all([v in ['Normal', 'No_label'] for v in x.values()]):\n",
    "        return ['Normal_or_No_Label']\n",
    "    \n",
    "    res_list = []\n",
    "    for k,v in x.items():\n",
    "        if v in ['Mild', 'Moderate', 'Severe', 'Present']:\n",
    "            res_list.append(f'{k}_Present')\n",
    "    res_list = list(set(res_list))\n",
    "    return res_list\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.858166Z",
     "start_time": "2024-07-31T12:17:52.826945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prep_meta(df: pd.DataFrame, \n",
    "              Target_maps: Dict,\n",
    "              use_multilabel: bool, \n",
    "              uni_model: bool,\n",
    "              multi_labels: Dict) -> [pd.DataFrame,pd.DataFrame]:\n",
    "    _multilabels = None\n",
    "    # Load the train/test hashes\n",
    "    test_hashes = pd.read_csv('./test_echoid.csv', sep=',')\n",
    "    train_hashes = pd.read_csv('./train_echoid.csv', sep=',')\n",
    "    print(train_hashes.columns)\n",
    "    \n",
    "    print(f\"Train hashes: {train_hashes.input_hash.nunique()}\")\n",
    "    print(f\"Test hashes: {test_hashes.input_hash.nunique()}\")\n",
    "    print(Target_maps.keys())\n",
    "    \n",
    "    \n",
    "    DF = df\n",
    "    DF.columns = ['sentence', 'labels', '_input_hash']\n",
    "    \n",
    "    if uni_model and use_multilabel:\n",
    "        label_set_list = set()\n",
    "        \n",
    "        for l in DF['labels'].values:\n",
    "            label_list = set()\n",
    "            for _l in l:\n",
    "                label_list.add(Target_maps[_l])\n",
    "            label_set_list.add(frozenset(label_list))\n",
    "            \n",
    "        _multilabels = {\n",
    "            k: list(s)\n",
    "            for k,s in enumerate(label_set_list)\n",
    "        }\n",
    "\n",
    "        _inverse_multilabels = {\n",
    "            tuple(s) : k\n",
    "            for k,s in _multilabels.items()\n",
    "        }        \n",
    "        def get_mc_id(x):\n",
    "            num_list = []\n",
    "            for _x in x:\n",
    "                num_list.append(Target_maps[_x])\n",
    "            tlist = tuple(set(num_list))\n",
    "            return _inverse_multilabels[tlist]\n",
    "        \n",
    "        id2label = {v:k for k,v in Target_maps.items()}\n",
    "        DF= DF.assign(labels=DF['labels'].apply(get_mc_id))\n",
    "        assert(DF['labels'].value_counts(dropna=True).sum() == DF.shape[0]), \"Something wrong with the id mapping? Not everything is mapped it seems\"\n",
    "\n",
    "    else:    \n",
    "        label2id = Target_maps\n",
    "        id2label = {v:k for k,v in label2id.items()}\n",
    "        num_labels = len(label2id)\n",
    "        DF['labels'] = DF['labels'].map(label2id)\n",
    "\n",
    "    \n",
    "    if filter_reports:\n",
    "        DF = DF.assign(sentence = echo_utils.report_filter(DF.sentence, \n",
    "                                                flag_terms=FLAG_TERMS, \n",
    "                                                save_terms=SAVE_TERMS)[0])\n",
    "        DF = DF.loc[DF.sentence.notna()]\n",
    "    \n",
    "    if deabbreviate:\n",
    "        DeAbber = deabber.deabber(model_type='sbert', \n",
    "                                  abbreviations=ABBREVIATIONS['nl']['echocardiogram'], \n",
    "                                  min_sim=0.5, \n",
    "                                  top_k=10)\n",
    "        DF = DF.assign(sentence=DeAbber.deabb(DF.sentence.values, TokenRadius=3))\n",
    "        \n",
    "    if use_multilabel:\n",
    "        if _multilabels is None:\n",
    "            if (multi_labels is not None):\n",
    "                _multilabels = {label2id[k]: [label2id[l] for l in v]\n",
    "                                for k,v in multi_labels.items()}\n",
    "            else:\n",
    "                raise(ValueError, \"No multilabels provided\")            \n",
    "    else:\n",
    "        _multilabels = None\n",
    "        \n",
    "    \n",
    "    # TODO: make proper\n",
    "    DFtrain = DF.loc[DF._input_hash.isin(train_hashes.input_hash.unique()), ['sentence', 'labels']]\n",
    "    DFtest = DF.loc[DF._input_hash.isin(test_hashes.input_hash.unique()), ['sentence', 'labels']]\n",
    "    \n",
    "    print(\"Train labels:\")\n",
    "    print(DFtrain.labels.value_counts())\n",
    "    print(\"Test labels:\")\n",
    "    print(DFtest.labels.value_counts())   \n",
    "\n",
    "    return DFtrain, DFtest, id2label, _multilabels\n",
    "\n",
    "def tokenize_meta(HFDataSet, tokenizer, num_labels, multilabels):\n",
    "    Tokenized_DataSet = HFDataSet.map(lambda batch: tokenizer(batch, truncation=True, \n",
    "                                                                      padding=True, \n",
    "                                                                      max_length=256),\n",
    "                                      input_columns='sentence',\n",
    "                                      batched=True,\n",
    "                                      remove_columns=['sentence'])\n",
    "    \n",
    "    Tokenized_DataSet = (Tokenized_DataSet\n",
    "                          #.map(lambda x : {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"])\n",
    "                          .map(lambda x: {\"labels\": \n",
    "                              multi_hot_encoding(x['labels'], \n",
    "                                                 multilabels=multilabels, \n",
    "                                                 num_classes=num_labels)}, \n",
    "                               batched=True, remove_columns=['labels']))                      \n",
    "                          #.rename_column(\"float_labels\", \"labels\"))\n",
    "    \n",
    "    Tokenized_DataSet.set_format(\"torch\", \n",
    "                                 columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    return Tokenized_DataSet, data_collator\n",
    "\n",
    "def get_trainer(compute_metrics=None, DataCollator=None, tokenizer=None, TokenizedDataSet=None, Target_maps=None, id2label=None, num_epochs=5):\n",
    "    # https://colab.research.google.com/drive/1aue7x525rKy6yYLqqt-5Ll96qjQvpqS7#scrollTo=1eVCRpcLUW-y\n",
    "    # https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
    "    \n",
    "    print(f\"Target map: {Target_maps}\")\n",
    "    print(f\"id2label: {id2label}\")\n",
    "    \n",
    "    medroberta_clf = AutoModelForSequenceClassification.from_pretrained(\"CLTL/MedRoBERTa.nl\", \n",
    "                                                    num_labels=len(id2label.keys()),\n",
    "                                                    problem_type='multi_label_classification',\n",
    "                                                    id2label=id2label,\n",
    "                                                    label2id=Target_maps)\n",
    "    \n",
    "    train_dir = \"T:\\\\laupodteam/AIOS/Bram/data/tmp\"\n",
    "    metric_name = 'f1_macro'\n",
    "    training_args = TrainingArguments(output_dir=train_dir,\n",
    "                                      evaluation_strategy='epoch',\n",
    "                                      save_strategy='epoch',\n",
    "                                      num_train_epochs=num_epochs,\n",
    "                                      learning_rate=5e-5,\n",
    "                                      per_device_train_batch_size=16,\n",
    "                                      weight_decay=0.01,\n",
    "                                      per_device_eval_batch_size=10,\n",
    "                                      load_best_model_at_end=True, \n",
    "                                      metric_for_best_model=metric_name)\n",
    "    \n",
    "    trainer = Trainer(medroberta_clf,\n",
    "                      training_args,\n",
    "                      train_dataset = TokenizedDataSet[\"train\"],\n",
    "                      eval_dataset = TokenizedDataSet[\"test\"],\n",
    "                      tokenizer=tokenizer,\n",
    "                      data_collator=DataCollator,\n",
    "                      compute_metrics=compute_metrics)\n",
    "    \n",
    "    return trainer, medroberta_clf"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.874071Z",
     "start_time": "2024-07-31T12:17:52.858166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inv_Target_maps = {v:k for k,v in Target_maps.items()}\n",
    "# \n",
    "# ClassCount = defaultdict(int)\n",
    "# for k,v in _multilabels.items():\n",
    "#     for _v in v:\n",
    "#         ClassCount[_v] += 1\n",
    "#         \n",
    "# test_label_count = defaultdict(int)\n",
    "# for l in DFtest.labels:\n",
    "#     for _l in _multilabels[l]:\n",
    "#         test_label_count[inv_Target_maps[_l]] += 1\n",
    "# sorted(test_label_count.items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:17:52.889756Z",
     "start_time": "2024-07-31T12:17:52.874071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test_label_count_str = defaultdict(int)\n",
    "# for l in labeled_documents.loc[labeled_documents._input_hash.isin(test_hashes.input_hash.unique()), 'labels']:\n",
    "#     for _l in l:\n",
    "#         test_label_count_str[_l] += 1\n",
    "# sorted(test_label_count_str.items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:34:54.243007Z",
     "start_time": "2024-07-31T12:17:52.889756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if uni_model==True:\n",
    "    # load merged..\n",
    "    labeled_documents = pd.read_json(f\"./echo_doc_labels/merged_labels.jsonl\", lines=True)\n",
    "    if uni_model_simple: # multiclass\n",
    "        print(\"Prepping uni model, simple...\")\n",
    "        labeled_documents['label'] = labeled_documents['labels'].apply(lab_dict_parser_simple)\n",
    "        labeled_documents = labeled_documents.drop('labels', axis=1)\n",
    "        labeled_documents=labeled_documents[['text', 'label', '_input_hash']]\n",
    "        Target_maps = {Label:i for i,Label in enumerate(labeled_documents['label'].unique())}\n",
    "        num_labels = len(Target_maps)\n",
    "    else: # multilabel\n",
    "        print(\"Prepping uni model, bespoke...\")\n",
    "        labeled_documents['label'] = labeled_documents['labels'].apply(lab_dict_parser_bespoke)\n",
    "        labeled_documents = labeled_documents.assign(label=labeled_documents['label'].apply(lambda x: list(set(x))))\n",
    "        labeled_documents = labeled_documents.drop('labels', axis=1)\n",
    "        labeled_documents=labeled_documents[['text', 'label', '_input_hash']]        \n",
    "        _labels = set()\n",
    "        for l in labeled_documents['label']:\n",
    "            for _l in l:\n",
    "                _labels.add(_l)\n",
    "        \n",
    "        Target_maps = {Label:i for i,Label in enumerate(_labels)}\n",
    "        num_labels = len(Target_maps)\n",
    "    \n",
    "    \n",
    "    DFtrain, DFtest, id2label, _multilabels = prep_meta(labeled_documents, Target_maps, \n",
    "                                                        use_multilabel=use_multilabel, \n",
    "                                                        uni_model=uni_model,\n",
    "                                                        multi_labels=None)\n",
    "    \n",
    "    TrainSet = Dataset.from_pandas(DFtrain)\n",
    "    TestSet = Dataset.from_pandas(DFtest)\n",
    "    \n",
    "    HF_DataSet = DatasetDict(\n",
    "        {'train' : TrainSet,\n",
    "         'test': TestSet,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    TokenizedDataSet, DataCollator = tokenize_meta(HF_DataSet, tokenizer, num_labels, _multilabels)\n",
    "    trainer, medroberta_clf = get_trainer(compute_metrics, DataCollator, tokenizer, TokenizedDataSet, Target_maps, id2label, num_epochs)   \n",
    "\n",
    "    trainer.train()\n",
    "    trainer.eval_dataset = TokenizedDataSet[\"test\"]\n",
    "    _metrics = trainer.evaluate()\n",
    "    \n",
    "    reduced_label_str = \"simple\" if uni_model_simple else \"bespoke\"\n",
    "    mod_string = f\"MultiModel_Epochs{num_epochs}_{reduced_label_str}\"   \n",
    "    new_dir = f\"T://lab_research/RES-Folder-UPOD/Echo_label/G_Output/3_OtherOutput/MedRoBERTa/{mod_string}\"\n",
    "    os.mkdir(new_dir)\n",
    "\n",
    "    trainer.save_model(new_dir)\n",
    "    trainer.save_metrics(new_dir, metrics=_metrics)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "elif uni_model==False:\n",
    "    for Class in Classes:\n",
    "        labeled_documents = pd.read_json(f\"./echo_doc_labels/{Class}.jsonl\", lines=True)\n",
    "        print(f\"Label counts: {labeled_documents.label.value_counts()}\")\n",
    "        if reduce_labels:\n",
    "            labeled_documents['label'] = labeled_documents.label.map(Target_remapper)\n",
    "            print(f\"Remapped labels: {labeled_documents.label.value_counts(dropna=False)}\")\n",
    "        # Expand with label columns\n",
    "        Target_maps = {Label:i for i,Label in enumerate(labeled_documents['label'].unique())}\n",
    "        num_labels = len(Target_maps)\n",
    "        \n",
    "        DFtrain, DFtest, id2label, _multilabels = prep_meta(labeled_documents, Target_maps, \n",
    "                                                            use_multilabel=use_multilabel,\n",
    "                                                            multi_labels=MULTILABELS)\n",
    "        \n",
    "        TrainSet = Dataset.from_pandas(DFtrain)\n",
    "        TestSet = Dataset.from_pandas(DFtest)\n",
    "        \n",
    "        HF_DataSet = DatasetDict(\n",
    "            {'train' : TrainSet,\n",
    "             'test': TestSet,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        TokenizedDataSet, DataCollator = tokenize_meta(tokenizer, num_labels, _multilabels)\n",
    "        \n",
    "        trainer, medroberta_clf = get_trainer(compute_metrics, DataCollator, tokenizer, TokenizedDataSet, Target_maps, id2label, num_epochs)\n",
    "    \n",
    "        \n",
    "        trainer.train()\n",
    "        trainer.eval_dataset = TokenizedDataSet[\"test\"]\n",
    "        _metrics = trainer.evaluate()\n",
    "        \n",
    "        \n",
    "        reduced_label_str = \"reduced_labels\" if reduce_labels else \"full_labels\"\n",
    "        mod_string = f\"{Class}_Epochs{num_epochs}_{reduced_label_str}\"\n",
    "        new_dir = f\"T://lab_research/RES-Folder-UPOD/Echo_label/G_Output/3_OtherOutput/MedRoBERTa/{mod_string}\"\n",
    "        os.mkdir(new_dir)\n",
    "        trainer.save_model(new_dir)\n",
    "        trainer.save_metrics(new_dir, metrics=_metrics)\n",
    "        \n",
    "        # clear GPU memory \n",
    "        del trainer, medroberta_clf    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()    trainer.save_model(new_dir)\n",
    "    trainer.save_metrics(new_dir, metrics=_metrics)\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping uni model, bespoke...\n",
      "Index(['ECHO_StudyID', 'ECHO_StudyID.1', 'input_hash', 'task_hash'], dtype='object')\n",
      "Train hashes: 96026\n",
      "Test hashes: 24051\n",
      "dict_keys(['pe_Present', 'rv_dil_Present', 'wma_Present', 'lv_dil_Present', 'aortic_valve_native_stenosis_Present', 'mitral_valve_native_regurgitation_Present', 'lv_sys_func_Present', 'rv_sys_func_Present', 'aortic_valve_native_regurgitation_Present', 'lv_dias_func_Present', 'Normal_or_No_Label', 'tricuspid_valve_native_regurgitation_Present'])\n",
      "Train labels:\n",
      "labels\n",
      "181    1315\n",
      "155     207\n",
      "74      203\n",
      "215     146\n",
      "45      115\n",
      "       ... \n",
      "20        1\n",
      "291       1\n",
      "302       1\n",
      "171       1\n",
      "97        1\n",
      "Name: count, Length: 313, dtype: int64\n",
      "Test labels:\n",
      "labels\n",
      "181    346\n",
      "155     47\n",
      "74      47\n",
      "45      34\n",
      "261     31\n",
      "      ... \n",
      "69       1\n",
      "18       1\n",
      "58       1\n",
      "19       1\n",
      "252      1\n",
      "Name: count, Length: 150, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3909 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9c4e3913fa641ca9ce2520382fbe6b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/958 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cd1e8943eed411aadaae9aa3b6e29bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3909 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae1b4b00b57d47ddaa9f669782755ef2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/958 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c52827b962074d6ba25e85cad0a375dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target map: {'pe_Present': 0, 'rv_dil_Present': 1, 'wma_Present': 2, 'lv_dil_Present': 3, 'aortic_valve_native_stenosis_Present': 4, 'mitral_valve_native_regurgitation_Present': 5, 'lv_sys_func_Present': 6, 'rv_sys_func_Present': 7, 'aortic_valve_native_regurgitation_Present': 8, 'lv_dias_func_Present': 9, 'Normal_or_No_Label': 10, 'tricuspid_valve_native_regurgitation_Present': 11}\n",
      "id2label: {0: 'pe_Present', 1: 'rv_dil_Present', 2: 'wma_Present', 3: 'lv_dil_Present', 4: 'aortic_valve_native_stenosis_Present', 5: 'mitral_valve_native_regurgitation_Present', 6: 'lv_sys_func_Present', 7: 'rv_sys_func_Present', 8: 'aortic_valve_native_regurgitation_Present', 9: 'lv_dias_func_Present', 10: 'Normal_or_No_Label', 11: 'tricuspid_valve_native_regurgitation_Present'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bes3\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\echolabeler-DyKQcQCO-py3.10\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at CLTL/MedRoBERTa.nl and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2450' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2450/2450 16:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Prec Weighted</th>\n",
       "      <th>Prec Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Weighted</th>\n",
       "      <th>Roc Auc Macro</th>\n",
       "      <th>Roc Auc Weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1 2</th>\n",
       "      <th>F1 3</th>\n",
       "      <th>F1 4</th>\n",
       "      <th>F1 5</th>\n",
       "      <th>F1 6</th>\n",
       "      <th>F1 7</th>\n",
       "      <th>F1 8</th>\n",
       "      <th>F1 9</th>\n",
       "      <th>F1 10</th>\n",
       "      <th>F1 11</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec 2</th>\n",
       "      <th>Prec 3</th>\n",
       "      <th>Prec 4</th>\n",
       "      <th>Prec 5</th>\n",
       "      <th>Prec 6</th>\n",
       "      <th>Prec 7</th>\n",
       "      <th>Prec 8</th>\n",
       "      <th>Prec 9</th>\n",
       "      <th>Prec 10</th>\n",
       "      <th>Prec 11</th>\n",
       "      <th>Recall 0</th>\n",
       "      <th>Recall 1</th>\n",
       "      <th>Recall 2</th>\n",
       "      <th>Recall 3</th>\n",
       "      <th>Recall 4</th>\n",
       "      <th>Recall 5</th>\n",
       "      <th>Recall 6</th>\n",
       "      <th>Recall 7</th>\n",
       "      <th>Recall 8</th>\n",
       "      <th>Recall 9</th>\n",
       "      <th>Recall 10</th>\n",
       "      <th>Recall 11</th>\n",
       "      <th>Auc 0</th>\n",
       "      <th>Auc 1</th>\n",
       "      <th>Auc 2</th>\n",
       "      <th>Auc 3</th>\n",
       "      <th>Auc 4</th>\n",
       "      <th>Auc 5</th>\n",
       "      <th>Auc 6</th>\n",
       "      <th>Auc 7</th>\n",
       "      <th>Auc 8</th>\n",
       "      <th>Auc 9</th>\n",
       "      <th>Auc 10</th>\n",
       "      <th>Auc 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.159194</td>\n",
       "      <td>0.637728</td>\n",
       "      <td>0.776969</td>\n",
       "      <td>0.845254</td>\n",
       "      <td>0.759917</td>\n",
       "      <td>0.584546</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.939218</td>\n",
       "      <td>0.963314</td>\n",
       "      <td>0.590814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.770686</td>\n",
       "      <td>0.946844</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.891641</td>\n",
       "      <td>0.937677</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.657258</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.318681</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.956647</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.750774</td>\n",
       "      <td>0.916520</td>\n",
       "      <td>0.960611</td>\n",
       "      <td>0.898779</td>\n",
       "      <td>0.974203</td>\n",
       "      <td>0.975238</td>\n",
       "      <td>0.992913</td>\n",
       "      <td>0.926543</td>\n",
       "      <td>0.951940</td>\n",
       "      <td>0.978117</td>\n",
       "      <td>0.983552</td>\n",
       "      <td>0.961431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.095848</td>\n",
       "      <td>0.808628</td>\n",
       "      <td>0.879381</td>\n",
       "      <td>0.938873</td>\n",
       "      <td>0.930650</td>\n",
       "      <td>0.737545</td>\n",
       "      <td>0.840692</td>\n",
       "      <td>0.982975</td>\n",
       "      <td>0.987126</td>\n",
       "      <td>0.732777</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.815287</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.956229</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.904025</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.966489</td>\n",
       "      <td>0.962885</td>\n",
       "      <td>0.979629</td>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.991613</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>0.993398</td>\n",
       "      <td>0.961318</td>\n",
       "      <td>0.992711</td>\n",
       "      <td>0.987383</td>\n",
       "      <td>0.993667</td>\n",
       "      <td>0.993949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.074570</td>\n",
       "      <td>0.898370</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.935785</td>\n",
       "      <td>0.917956</td>\n",
       "      <td>0.882313</td>\n",
       "      <td>0.924224</td>\n",
       "      <td>0.986289</td>\n",
       "      <td>0.989639</td>\n",
       "      <td>0.821503</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.907850</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>0.963696</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.950226</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.930070</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.938889</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.968208</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.954171</td>\n",
       "      <td>0.972401</td>\n",
       "      <td>0.984587</td>\n",
       "      <td>0.983219</td>\n",
       "      <td>0.997408</td>\n",
       "      <td>0.994578</td>\n",
       "      <td>0.993191</td>\n",
       "      <td>0.979317</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>0.994107</td>\n",
       "      <td>0.990314</td>\n",
       "      <td>0.996564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.068588</td>\n",
       "      <td>0.901882</td>\n",
       "      <td>0.931510</td>\n",
       "      <td>0.939181</td>\n",
       "      <td>0.909999</td>\n",
       "      <td>0.895535</td>\n",
       "      <td>0.925418</td>\n",
       "      <td>0.987983</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.824635</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.892086</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.953425</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.950673</td>\n",
       "      <td>0.944282</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.971883</td>\n",
       "      <td>0.966079</td>\n",
       "      <td>0.991180</td>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.998297</td>\n",
       "      <td>0.994439</td>\n",
       "      <td>0.993251</td>\n",
       "      <td>0.978416</td>\n",
       "      <td>0.994083</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.998194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.064220</td>\n",
       "      <td>0.905146</td>\n",
       "      <td>0.934501</td>\n",
       "      <td>0.945944</td>\n",
       "      <td>0.927072</td>\n",
       "      <td>0.886369</td>\n",
       "      <td>0.924821</td>\n",
       "      <td>0.987168</td>\n",
       "      <td>0.990341</td>\n",
       "      <td>0.834029</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.900709</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.947658</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>0.959641</td>\n",
       "      <td>0.935294</td>\n",
       "      <td>0.958153</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.956772</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.970199</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.964262</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>0.991469</td>\n",
       "      <td>0.984157</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.997139</td>\n",
       "      <td>0.994412</td>\n",
       "      <td>0.982662</td>\n",
       "      <td>0.993067</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.991027</td>\n",
       "      <td>0.998895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.060129</td>\n",
       "      <td>0.911228</td>\n",
       "      <td>0.938428</td>\n",
       "      <td>0.940141</td>\n",
       "      <td>0.911277</td>\n",
       "      <td>0.911992</td>\n",
       "      <td>0.937351</td>\n",
       "      <td>0.989039</td>\n",
       "      <td>0.991120</td>\n",
       "      <td>0.844468</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.920962</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.958449</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.945559</td>\n",
       "      <td>0.963610</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.926966</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.956647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>0.972269</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>0.984942</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.994592</td>\n",
       "      <td>0.994437</td>\n",
       "      <td>0.982993</td>\n",
       "      <td>0.996335</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>0.999070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.060926</td>\n",
       "      <td>0.917705</td>\n",
       "      <td>0.940102</td>\n",
       "      <td>0.943630</td>\n",
       "      <td>0.926551</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.937351</td>\n",
       "      <td>0.988704</td>\n",
       "      <td>0.991096</td>\n",
       "      <td>0.849687</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.902128</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.959654</td>\n",
       "      <td>0.958580</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.936047</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.963576</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.964123</td>\n",
       "      <td>0.973744</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.984271</td>\n",
       "      <td>0.998526</td>\n",
       "      <td>0.994702</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>0.984065</td>\n",
       "      <td>0.994994</td>\n",
       "      <td>0.992584</td>\n",
       "      <td>0.989148</td>\n",
       "      <td>0.999191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.059564</td>\n",
       "      <td>0.922314</td>\n",
       "      <td>0.942501</td>\n",
       "      <td>0.947219</td>\n",
       "      <td>0.930277</td>\n",
       "      <td>0.915295</td>\n",
       "      <td>0.938544</td>\n",
       "      <td>0.988825</td>\n",
       "      <td>0.990902</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.975042</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.938416</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.970199</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.935673</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>0.971520</td>\n",
       "      <td>0.992731</td>\n",
       "      <td>0.984119</td>\n",
       "      <td>0.998424</td>\n",
       "      <td>0.994928</td>\n",
       "      <td>0.993615</td>\n",
       "      <td>0.985807</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.992250</td>\n",
       "      <td>0.988723</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>0.914460</td>\n",
       "      <td>0.939578</td>\n",
       "      <td>0.947233</td>\n",
       "      <td>0.930203</td>\n",
       "      <td>0.900532</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.988341</td>\n",
       "      <td>0.990766</td>\n",
       "      <td>0.845511</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.959654</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.966698</td>\n",
       "      <td>0.967797</td>\n",
       "      <td>0.993870</td>\n",
       "      <td>0.984271</td>\n",
       "      <td>0.998450</td>\n",
       "      <td>0.994607</td>\n",
       "      <td>0.993372</td>\n",
       "      <td>0.985267</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.991120</td>\n",
       "      <td>0.989355</td>\n",
       "      <td>0.999421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>0.917112</td>\n",
       "      <td>0.940050</td>\n",
       "      <td>0.944771</td>\n",
       "      <td>0.924373</td>\n",
       "      <td>0.910709</td>\n",
       "      <td>0.936158</td>\n",
       "      <td>0.989182</td>\n",
       "      <td>0.991133</td>\n",
       "      <td>0.847599</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.891775</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.941520</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.967777</td>\n",
       "      <td>0.974273</td>\n",
       "      <td>0.994257</td>\n",
       "      <td>0.984144</td>\n",
       "      <td>0.998526</td>\n",
       "      <td>0.994731</td>\n",
       "      <td>0.993620</td>\n",
       "      <td>0.986198</td>\n",
       "      <td>0.996209</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.999380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:04]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Kan geen bestand maken dat al bestaat: 'T://lab_research/RES-Folder-UPOD/Echo_label/G_Output/3_OtherOutput/MedRoBERTa/MultiModel_Epochs10_bespoke'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 50\u001B[0m\n\u001B[0;32m     48\u001B[0m mod_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMultiModel_Epochs\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mreduced_label_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m   \n\u001B[0;32m     49\u001B[0m new_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT://lab_research/RES-Folder-UPOD/Echo_label/G_Output/3_OtherOutput/MedRoBERTa/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmod_string\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 50\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(new_dir)\n\u001B[0;32m     53\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_metrics(new_dir, metrics\u001B[38;5;241m=\u001B[39m_metrics)\n",
      "\u001B[1;31mFileExistsError\u001B[0m: [WinError 183] Kan geen bestand maken dat al bestaat: 'T://lab_research/RES-Folder-UPOD/Echo_label/G_Output/3_OtherOutput/MedRoBERTa/MultiModel_Epochs10_bespoke'"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:50:28.628517Z",
     "start_time": "2024-07-31T12:50:28.597272Z"
    }
   },
   "cell_type": "code",
   "source": "Target_maps",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pe_Present': 0,\n",
       " 'rv_dil_Present': 1,\n",
       " 'wma_Present': 2,\n",
       " 'lv_dil_Present': 3,\n",
       " 'aortic_valve_native_stenosis_Present': 4,\n",
       " 'mitral_valve_native_regurgitation_Present': 5,\n",
       " 'lv_sys_func_Present': 6,\n",
       " 'rv_sys_func_Present': 7,\n",
       " 'aortic_valve_native_regurgitation_Present': 8,\n",
       " 'lv_dias_func_Present': 9,\n",
       " 'Normal_or_No_Label': 10,\n",
       " 'tricuspid_valve_native_regurgitation_Present': 11}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# consider quantisation using bitsandbytes or quanto",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
